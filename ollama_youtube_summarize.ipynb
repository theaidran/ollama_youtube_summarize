{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/theaidran/ollama_youtube_summarize/blob/main/ollama_youtube_summarize.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title #####  Put a YouTube link below and hit Run a cell. Use any-language video and get any-language summary. Quick access to this colab notebook. [tinyurl.com/summarisation](https://tinyurl.com/summarisation) { display-mode: \"form\" }\n",
        "%config InteractiveShell.ast_node_interactivity=\"all\" #update python display config"
      ],
      "metadata": {
        "collapsed": true,
        "id": "PddpLm1hdgvN"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jwROe6WH2lZi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "86be2c86-c049-4a17-a666-bce4defbd981"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n\n **Short Summary:** \n\n00:00:00 - https://www.youtube.com/watch?v=t6VoqbAh9HM&t=0 **Generating Content with AI: A Step-by-Step Guide**\n\nIn this video transcript excerpt, the speaker discusses using artificial intelligence (AI) tools like ChatGPT and Claude to generate content for their website. They start by writing a prompt that provides details about their site, which reviews drones, and specify what they need - website copies that will entice visitors to use the site.\n\nTo generate the content, the speaker uses Claude and creates a header and subheader in the style of Alex Horoi and David Ogili. The AI tool produces a heading \"The Ultimate Drone Buyer Guide: Soaring to New Heights with the Perfect UAV\" and a subheading \"Discover the Best Drones for Your Needs and Budget: Expert Reviews, Side-by-Side Comparisons, and Insider Tips to Help You Make an Informed Decision\".\n\nThe speaker then uses this generated content as the heading and subheading on their website. They also explore using AI tools like Mid Journey and Dolly 3 to generate images for their website, including a popular camera drone flying above a city skyline.\n\nFinally, they discuss creating featured images for blog posts using Canva, which is easy to use and allows them to add text, remove backgrounds, and manipulate image elements. Overall, the speaker provides a step-by-step guide on how to utilize AI tools to generate content for their website, making it more engaging and informative for visitors.\n\n\n00:11:15 - https://www.youtube.com/watch?v=t6VoqbAh9HM&t=675 **Creating a Featured Image Using Canva's AI Features**\n\nAs the narrator continues to showcase the power of AI tools, he delves into creating a featured image using Canva. He starts by clicking on \"Create a design\" and selecting the option to create a YouTube thumbnail, which is also suitable for blog featured images. The narrator then uses Canva's Magic Media feature to generate an image based on his preferences, in this case, a camera drone flying above a city skyline. He right-clicks on the generated image and sets it as the background, adding some personal touch by uploading an image of himself pointing at the drone.\n\nTo make himself stand out, he uses AI to remove the background from the uploaded image and adds a white outline around him. He then selects the font \"Roboto Condensed\" for the text overlay, which is consistent with his website's style. Finally, he saves the featured image as a JPEG and downloads it, ready to be used on his website.\n\nThis segment highlights how AI can streamline the process of creating high-quality featured images for blog posts, making it easier to maintain consistency across the site.\n\n\n\n\n **Long Summary:** \n\n00:00:00 - https://www.youtube.com/watch?v=t6VoqbAh9HM&t=0 **\"AI-Enabled Website Building Tools: Getting Started with Reloom\"**\n\nThe conversation continues, discussing AI-enabled tools for building websites without requiring technical knowledge. The speaker emphasizes the importance of having a website and highlights Reloom as a valuable tool for mapping out an entire site using artificial intelligence. With Reloom, users can create a simple website on the free plan or upgrade to premium plans that integrate with web design tools like Webflow and Figma.\n\nThe speaker walks viewers through creating a new project in Reloom, starting by entering a prompt about their website's content. In this example, they're building a site reviewing and comparing camera drones. After clicking \"Generate Site Map,\" the AI starts to build out a basic layout for the homepage and subsequent pages, including hero sections, feature lists, reviews, pricing information, testimonials, FAQs, and footers.\n\nThe speaker then demonstrates how to generate content for each page using Reloom's AI capabilities. They can click on individual Pages to create design concepts and even scroll through wireframes to get a rough idea of what the site will look like.\n\n\n00:02:18 - https://www.youtube.com/watch?v=t6VoqbAh9HM&t=138 **Building a Website with Hostinger's AI Tool**\n\nAs we continue, we're now focusing on building a website using Hostinger's AI-powered tool. After selecting the Business website builder plan, we can choose to let AI create our website in minutes. We enter the coupon code \"Matt wolf\" and click apply to receive an even bigger discount.\n\nOnce inside the hosting or website builder, we select the option to let AI create our website. We input the brand name \"Drone World\", choose a blog format for the description, and speak out the description for our website - a platform that compares and reviews camera drones to help consumers make informed decisions.\n\nWith just a few clicks, AI sets everything up for us, and we have a live website already titled \"Drone World\" with automatically pulled-in pictures of drone photography. Now, let's edit the site and change anything we want, starting with the color scheme using ColorMind, a tool that utilizes machine learning technology...\n\n\n00:04:34 - https://www.youtube.com/watch?v=t6VoqbAh9HM&t=274 **Elevating Website Design with AI: Color Palette Generation**\n\nThe speaker is using Colormind, an AI-powered tool, to generate a color palette for their website. They start by generating a random palette and then lock in the colors they like, which are a blue, yellow, and red. By locking these colors in, the AI generates more variations that match well with the selected design. The speaker is pleased with the result and uses the generated codes to apply the color scheme to their website.\n\n**Font Selection: A Perfect Match**\n\nNext, the speaker turns their attention to font selection using Fontjoy, another AI-powered tool. They sit through a few different font styles until they find one that stands out - Robotto Condensed. They lock this font in and then use the AI to generate other fonts that pair well with it. After a couple of clicks, they're satisfied with their findings and select the new font for their website's headers and subheadings.\n\n\n00:06:48 - https://www.youtube.com/watch?v=t6VoqbAh9HM&t=408 **Crafting Website Content with AI**\n\nThe speaker is continuing to work on building their website, focusing on creating the content section. They're using AI tools like ChatGPT or Claude to generate the text, as they've already established a font pairing and color scheme. The goal is to create engaging copy that will encourage visitors to use the site. To achieve this, the speaker starts by giving details about their website, which reviews and compares drones to help consumers make informed decisions. They then provide specific instructions for the AI tool, including writing a header and subheader in the style of Alex Horoi and David Ogie.\n\n\n00:09:01 - https://www.youtube.com/watch?v=t6VoqbAh9HM&t=541 **Website Optimization Strategies**\n\nAs our conversation continues, we're discussing the importance of optimizing website headings and subheadings. We've learned that it's crucial to repeat this step for each section of your website, making sure to copy and replace the heading and subheading as needed.\n\nThe speaker also highlights the need for high-quality images throughout the website. While they appreciate the image used in this example, they want to generate more images using tools like Mid Journey, Dolly 3, or Canva. These tools allow users to create realistic images with a personal touch, making them more effective for enhancing website content.\n\nWe've also explored how to edit and customize these generated images using settings like model raw and adjusting the image size. The speaker shares their experience in generating and editing an image of a drone flying over a city skyline, replacing the original image on the website.\n\nIn addition to optimizing headings and subheadings, we've touched on the importance of creating relevant featured images for blog posts. Canva is presented as a favorite tool for this task, allowing users to add text overlays, remove backgrounds, and edit images with ease.\n\n\n00:11:27 - https://www.youtube.com/watch?v=t6VoqbAh9HM&t=687 **Creating Consistent Featured Images with Canva**\n\nAs the speaker navigates through Canva, they're looking for ways to create consistent featured images for their blog posts. They start by exploring the Magic media option and using the built-in image generator to create custom graphics. After generating a few options, they choose one that resembles a drone flying above a city skyline, which will serve as the background for their featured image.\n\nNext, they select an image of themselves pointing, but it has a background that needs to be removed. They use Canva's AI-powered background remover tool (available only in the paid version) to remove the unwanted background and create a clean image of themselves. To make themselves stand out more, they add a white outline around their figure.\n\nFinally, the speaker adds text to the image, selecting the \"Roboto Condensed\" font style to match their website's branding. They stretch out the text to cover the entire image, creating a visually appealing featured image for their blog post.\n\n\n00:13:31 - https://www.youtube.com/watch?v=t6VoqbAh9HM&t=811 **Building a Website with AI: The Ultimate Guide**\n\nAs the creator of the website continues, they highlight the importance of adding visual effects to make their featured image \"pop off the screen.\" They use Canva's AI features to create the image, adding a drop shadow effect to give it depth. With the image saved as a JPEG, they jump back to their website and replace the previous featured image with the new one.\n\nThe creator notes that they've used various AI tools throughout the process, including Reloom for site mapping, Hostinger (with a coupon code) for building the website itself, ColorMind for figuring out a color scheme, FontJoy for font pairings, and either ChatGPT or Claude for writing copy. They also used an image generator to generate images for the website.\n\nThe final step is creating featured images for blog posts using Canva. The creator emphasizes that while AI can't yet produce a beautiful, polished website from scratch, it's possible to get very close with the right tools and some extra tweaking.\n\n\n00:15:55 - https://www.youtube.com/watch?v=t6VoqbAh9HM&t=955 **Staying Up-to-Date on AI Tools and News**\n\nThe speaker is encouraging viewers to check out Future Tools, a platform that curates cool AI tools and keeps users up-to-date on the latest AI news. The channel's YouTube page features new updates almost daily, with a free newsletter sent to subscribers with the coolest tools and most important news. As an added incentive, the speaker will be giving away free gadgets each month to subscribers of both the YouTube channel and the Future Tools newsletter.\n\nTo enter the drawing for this month's prize, an Insta 360 X4 camera, viewers must simply subscribe to the YouTube channel and join the free newsletter at Future Tools. This is not a one-time offer; every single month, the speaker will be giving away more cool gadgets to subscribers of both platforms. The goal is to provide valuable tools and inspiration to those building websites or working on creative projects.\n"
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# @title  Summarize { run: \"auto\", display-mode: \"form\" }\n",
        "# All credits to https://github.com/martinopiaggi/summarize\n",
        "# Good to see links:\n",
        "# https://github.com/hsiehjackson/RULER\n",
        "# https://ollama.com/library\n",
        "# https://amgadhasan.substack.com/p/sota-asr-tooling-long-form-transcription\n",
        "\n",
        "\n",
        "#1 Choose source url\n",
        "Link = \"https://www.youtube.com/watch?v=t6VoqbAh9HM\" #@param {type:\"string\"}\n",
        "Type_of_source = \"Youtube video or playlist\" #@param ['Youtube video or playlist', 'Google Drive video link','Dropbox video link', 'Local file']\n",
        "Type = Type_of_source\n",
        "URL = Link\n",
        "Translate_to = \"English\" # @param ['Afrikaans', 'Albanian', 'Amharic', 'Arabic', 'Armenian', 'Azerbaijani', 'Basque', 'Belarusian', 'Bengali', 'Bosnian', 'Bulgarian', 'Catalan', 'Cebuano', 'Chinese (Simplified)', 'Chinese (Traditional)', 'Corsican', 'Croatian', 'Czech', 'Danish', 'Dutch', 'English', 'Esperanto', 'Estonian', 'Finnish', 'French', 'Frisian', 'Galician', 'Georgian', 'German', 'Greek', 'Gujarati', 'Haitian Creole', 'Hausa', 'Hawaiian', 'Hebrew', 'Hindi', 'Hmong', 'Hungarian', 'Icelandic', 'Igbo', 'Indonesian', 'Irish', 'Italian', 'Japanese', 'Javanese', 'Kannada', 'Kazakh', 'Khmer', 'Korean', 'Kurdish', 'Kyrgyz', 'Lao', 'Latin', 'Latvian', 'Lithuanian', 'Luxembourgish', 'Macedonian', 'Malagasy', 'Malay', 'Malayalam', 'Maltese', 'Maori', 'Marathi', 'Mongolian', 'Myanmar (Burmese)', 'Nepali', 'Norwegian', 'Nyanja (Chichewa)', 'Pashto', 'Persian', 'Polish', 'Portuguese (Portugal, Brazil)', 'Punjabi', 'Romanian', 'Russian', 'Samoan', 'Scots Gaelic', 'Serbian', 'Sesotho', 'Shona', 'Sindhi', 'Sinhala (Sinhalese)', 'Slovak', 'Slovenian', 'Somali', 'Spanish', 'Sundanese', 'Swahili', 'Swedish', 'Tagalog (Filipino)', 'Tajik', 'Tamil', 'Telugu', 'Thai', 'Turkish', 'Ukrainian', 'Urdu', 'Uzbek', 'Vietnamese', 'Welsh', 'Xhosa', 'Yiddish', 'Yoruba', 'Zulu']\n",
        "\n",
        "language_codes = {'Afrikaans': 'af', 'Albanian': 'sq', 'Amharic': 'am', 'Arabic': 'ar', 'Armenian': 'hy', 'Azerbaijani': 'az', 'Basque': 'eu', 'Belarusian': 'be', 'Bengali': 'bn', 'Bosnian': 'bs', 'Bulgarian': 'bg', 'Catalan': 'ca', 'Cebuano': 'ceb', 'Chinese (Simplified)': 'zh-CN', 'Chinese (Traditional)': 'zh-TW', 'Corsican': 'co', 'Croatian': 'hr', 'Czech': 'cs', 'Danish': 'da', 'Dutch': 'nl', 'English': 'en', 'Esperanto': 'eo', 'Estonian': 'et', 'Finnish': 'fi', 'French': 'fr', 'Frisian': 'fy', 'Galician': 'gl', 'Georgian': 'ka', 'German': 'de', 'Greek': 'el', 'Gujarati': 'gu', 'Haitian Creole': 'ht', 'Hausa': 'ha', 'Hawaiian': 'haw', 'Hebrew': 'iw', 'Hindi': 'hi', 'Hmong': 'hmn', 'Hungarian': 'hu', 'Icelandic': 'is', 'Igbo': 'ig', 'Indonesian': 'id', 'Irish': 'ga', 'Italian': 'it', 'Japanese': 'ja', 'Javanese': 'jw', 'Kannada': 'kn', 'Kazakh': 'kk', 'Khmer': 'km', 'Korean': 'ko', 'Kurdish': 'ku', 'Kyrgyz': 'ky', 'Lao': 'lo', 'Latin': 'la', 'Latvian': 'lv', 'Lithuanian': 'lt', 'Luxembourgish': 'lb', 'Macedonian': 'mk', 'Malagasy': 'mg', 'Malay': 'ms', 'Malayalam': 'ml', 'Maltese': 'mt', 'Maori': 'mi', 'Marathi': 'mr', 'Mongolian': 'mn', 'Myanmar (Burmese)': 'my', 'Nepali': 'ne', 'Norwegian': 'no', 'Nyanja (Chichewa)': 'ny', 'Pashto': 'ps', 'Persian': 'fa', 'Polish': 'pl', 'Portuguese (Portugal, Brazil)': 'pt', 'Punjabi': 'pa', 'Romanian': 'ro', 'Russian': 'ru', 'Samoan': 'sm', 'Scots Gaelic': 'gd', 'Serbian': 'sr', 'Sesotho': 'st', 'Shona': 'sn', 'Sindhi': 'sd', 'Sinhala (Sinhalese)': 'si', 'Slovak': 'sk', 'Slovenian': 'sl', 'Somali': 'so', 'Spanish': 'es', 'Sundanese': 'su', 'Swahili': 'sw', 'Swedish': 'sv', 'Tagalog (Filipino)': 'tl', 'Tajik': 'tg', 'Tamil': 'ta', 'Telugu': 'te', 'Thai': 'th', 'Turkish': 'tr', 'Ukrainian': 'uk', 'Urdu': 'ur', 'Uzbek': 'uz', 'Vietnamese': 'vi', 'Welsh': 'cy', 'Xhosa': 'xh', 'Yiddish': 'yi', 'Yoruba': 'yo', 'Zulu': 'zu'}\n",
        "\n",
        "#@markdown ---\n",
        "#markdown Insert your API key depending on which endpoint you want to use\n",
        "# API Configuration\n",
        "api_key = \"ollama\"\n",
        "api_endpoint = \"Custom\"\n",
        "ollama_model = \"llama3\" # param ['llama3', 'phi3', 'vicuna:13b-v1.5-16k-q4_0']\n",
        "\n",
        "endpoints = {\n",
        "    \"Groq\": \"https://api.groq.com/openai/v1\",\n",
        "    \"OpenAI\": \"https://api.openai.com/v1\",\n",
        "    \"Custom\": \"http://localhost:11434/v1\"  # ollama endpoint\n",
        "}\n",
        "base_url = endpoints.get(api_endpoint)\n",
        "\n",
        "models = {\n",
        "    \"Groq\": \"llama3-8b-8192\",\n",
        "    \"OpenAI\": \"gpt-3.5-turbo\",\n",
        "    \"Custom\": ollama_model  # Placeholder for any custlom model\n",
        "}\n",
        "model = models.get(api_endpoint)\n",
        "\n",
        "use_Youtube_captions = True #@param {type:\"boolean\"}\n",
        "# @markdown  * otherwise transcribe audio\n",
        "\n",
        "\n",
        "#2 launch ollama server with llama3\n",
        "try: # to faster next start\n",
        "  import pytubefix\n",
        "except ImportError:\n",
        "  !curl -fsSL https://ollama.com/install.sh | sh\n",
        "  !tmux new -d ollama serve\n",
        "  !ollama run {ollama_model} !\n",
        "\n",
        "\n",
        "#3 install libs: youtube and whisperx\n",
        "import subprocess\n",
        "import re\n",
        "import os\n",
        "import IPython\n",
        "from IPython.display import clear_output\n",
        "\n",
        "def install_whisperx():\n",
        "    try:\n",
        "      import whisperx\n",
        "    except ImportError:\n",
        "      print(\"installing whisperx...may take a few minutes\")\n",
        "      !pip install git+https://github.com/m-bain/whisperx.git > /dev/null\n",
        "      clear_output()\n",
        "\n",
        "if use_Youtube_captions:\n",
        "  !pip install youtube-transcript-api\n",
        "  from youtube_transcript_api import YouTubeTranscriptApi\n",
        "\n",
        "if (not Type == \"Youtube video or playlist\") or (not use_Youtube_captions):\n",
        "  install_whisperx()\n",
        "\n",
        "try:\n",
        "  import deep_translator\n",
        "except ImportError:\n",
        "  !pip install -U deep-translator\n",
        "\n",
        "try:\n",
        "  import openai\n",
        "except ImportError:\n",
        "  !pip install openai\n",
        "  #clear_output()\n",
        "\n",
        "import openai\n",
        "client = openai.OpenAI(api_key=api_key, base_url=base_url)\n",
        "\n",
        "if Type == \"Youtube video or playlist\":\n",
        "  try:\n",
        "    import pytubefix\n",
        "  except ImportError:\n",
        "    #!pip install git+https://github.com/pytube/pytube\n",
        "    !pip install git+https://github.com/JuanBindez/pytubefix\n",
        "    #clear_output()\n",
        "    from pytubefix import YouTube\n",
        "\n",
        "if Type == \"Google Drive video link\":\n",
        "  from google.colab import drive\n",
        "  drive.mount('/gdrive')\n",
        "\n",
        "#4 Video fetching\n",
        "skip_transcription=False\n",
        "text = \"\"\n",
        "textTimestamps = \"\"\n",
        "\n",
        "def seconds_to_time_format(seconds):\n",
        "    hours, remainder = divmod(seconds, 3600)\n",
        "    minutes, seconds = divmod(remainder, 60)\n",
        "    return f\"{int(hours):02d}:{int(minutes):02d}:{int(seconds):02d}\"\n",
        "\n",
        "def download_youtube_audio_only(url):\n",
        "    yt = YouTube(url)\n",
        "    audio_stream = yt.streams.get_audio_only()\n",
        "    saved_path = audio_stream.download(output_path=\".\", skip_existing=True)\n",
        "    return saved_path\n",
        "\n",
        "def check_if_captions_exist(url):\n",
        "    regex = r'(?:https?:\\/\\/)?(?:www\\.)?(?:youtube\\.com\\/(?:[^\\/\\n\\s]+\\/\\S+\\/|(?:v|e(?:mbed)?)\\/|\\S*?[?&]v=)|youtu\\.be\\/)([a-zA-Z0-9_-]{11})'\n",
        "    video_id =  re.search(regex, url).group(1)\n",
        "\n",
        "    try:\n",
        "      transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\n",
        "      return (True)\n",
        "    except:\n",
        "      return (False)\n",
        "\n",
        "def download_youtube_captions(url):\n",
        "    regex = r'(?:https?:\\/\\/)?(?:www\\.)?(?:youtube\\.com\\/(?:[^\\/\\n\\s]+\\/\\S+\\/|(?:v|e(?:mbed)?)\\/|\\S*?[?&]v=)|youtu\\.be\\/)([a-zA-Z0-9_-]{11})'\n",
        "    video_id =  re.search(regex, url).group(1)\n",
        "    transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\n",
        "\n",
        "    try:\n",
        "      transcript = YouTubeTranscriptApi.get_transcript(video_id) #languages=['en']\n",
        "    except:\n",
        "      for available_transcript in transcript_list:\n",
        "        if available_transcript.is_translatable:\n",
        "          transcript = available_transcript.translate('en').fetch()\n",
        "          break\n",
        "\n",
        "    text = \"\"\n",
        "    for entry in transcript:\n",
        "            start_time = seconds_to_time_format(entry['start'])\n",
        "            text += f\"{start_time} {entry['text'].strip()}\\n\"\n",
        "\n",
        "    transcript_file_name = f\"{video_id}_captions.md\"\n",
        "\n",
        "    with open(transcript_file_name, 'w', encoding='utf-8') as f:\n",
        "      f.write(text)\n",
        "\n",
        "    return text,transcript_file_name\n",
        "\n",
        "if Type == \"Youtube video or playlist\":\n",
        "    #clean youtube url from timestamp\n",
        "    URL = re.sub('\\&t=\\d+s?', '', URL)\n",
        "\n",
        "    if use_Youtube_captions and check_if_captions_exist(URL):\n",
        "      text, transcript_file_name = download_youtube_captions(URL)\n",
        "      skip_transcription=True\n",
        "    else:\n",
        "      install_whisperx()\n",
        "      video_path_local =  download_youtube_audio_only(URL)\n",
        "\n",
        "elif Type == \"Google Drive video link\":\n",
        "  subprocess.run(['ffmpeg', '-y', '-i', '/gdrive/My Drive/' + URL, '-vn', '-acodec', 'pcm_s16le',\n",
        "                  '-ar', '16000', '-ac', '1', 'gdrive_audio.wav'], check=True)\n",
        "  video_path_local = \"gdrive_audio.wav\"\n",
        "\n",
        "elif Type == \"Dropbox video link\":\n",
        "    subprocess.run(['wget', URL, '-O', 'dropbox_video.mp4'], check=True)\n",
        "    subprocess.run(['ffmpeg', '-y', '-i', 'dropbox_video.mp4', '-vn', '-acodec', 'pcm_s16le',\n",
        "                    '-ar', '16000', '-ac', '1', 'dropbox_video_audio.wav'], check=True)\n",
        "    video_path_local = \"dropbox_video_audio.wav\"\n",
        "\n",
        "elif Type == \"Local file\":\n",
        "    local_file_path = Source\n",
        "    subprocess.run(['ffmpeg', '-y', '-i', local_file_path, '-vn', '-acodec', 'pcm_s16le',\n",
        "                    '-ar', '16000', '-ac', '1', 'local_file_audio.wav'], check=True)\n",
        "    video_path_local = \"local_file_audio.wav\"\n",
        "\n",
        "\n",
        "#5 transcription using whisperx\n",
        "if not skip_transcription:\n",
        "  import whisperx\n",
        "  language = \"auto\" # param {type:\"string\"}\n",
        "  #initial_prompt = \"\" # @param {type:\"string\"}\n",
        "\n",
        "  asr_options={\"temperatures\": 0, \"beam_size\": 1, \"without_timestamps\": True,}\n",
        "  # Run on GPU with FP16\n",
        "  modelWhisperX = whisperx.load_model(\"large-v2\", device=\"cuda\", compute_type=\"float16\", asr_options=asr_options)\n",
        "\n",
        "  transcription = modelWhisperX.transcribe(str(video_path_local), batch_size=16,\n",
        "                                    language=None if language == \"auto\" else language,\n",
        "                                    task=\"translate\")\n",
        "\n",
        "  transcript_file_name = os.path.splitext(video_path_local)[0]+'.md'\n",
        "\n",
        "  with open(transcript_file_name, 'w') as f:\n",
        "    for segment in transcription[\"segments\"]:\n",
        "        start_time = seconds_to_time_format(segment['start'])\n",
        "        text += f\"{start_time} {segment['text'].strip()} \"\n",
        "\n",
        "    f.write(text)\n",
        "\n",
        "\n",
        "#6 Make a summary\n",
        "prompt_type = \"Summarization\"  # param ['Summarization', 'Only grammar correction with highlights']\n",
        "# markdown Set the number of parallel API calls (be mindful of usage rate limits)\n",
        "parallel_api_calls = 1 # param\n",
        "\n",
        "\n",
        "# Define your prompts using a dictionary for easier management\n",
        "prompts = {\n",
        "    'Summarization': \"\"\"Summarize the video transcript excerpt, including a bold title. Use narration in third-person. Write the summary as if you are continuing a conversation without needing to signal a beginning. Here is the transcript: \"\"\",\n",
        "    'Only grammar correction with highlights': \"\"\"Repeat the following text correcting any grammatical errors and formatting error. Highlight only the important quote (if there are any) with **markdown bold notation**. Focus solely on the essence of the content as if you are continuing a conversation without using any form of introduction like 'Here's the corrected text:'. Here is the text to fix: \"\"\"\n",
        "}\n",
        "\n",
        "# Select the appropriate prompt\n",
        "summary_prompt = prompts[prompt_type]\n",
        "\n",
        "\n",
        "\n",
        "def extract_and_clean_timestamps(text_chunks):\n",
        "    timestamp_pattern = re.compile(r'(\\d{2}:\\d{2}:\\d{2})')\n",
        "    cleaned_texts = []\n",
        "    timestamp_ranges = []\n",
        "    for chunk in text_chunks:\n",
        "        timestamps = timestamp_pattern.findall(chunk)\n",
        "        if timestamps:\n",
        "            for timestamp in timestamps:\n",
        "                # Remove each found timestamp from the chunk\n",
        "                chunk = chunk.replace(timestamp, \"\")\n",
        "            timestamp_ranges.append(timestamps[0])  # Assuming you want the first timestamp per chunk\n",
        "        else:\n",
        "            timestamp_ranges.append(\"\")\n",
        "        cleaned_texts.append(chunk.strip())  # Strip to remove any leading/trailing whitespace\n",
        "    return cleaned_texts, timestamp_ranges\n",
        "\n",
        "def format_timestamp_link(timestamp):\n",
        "    if Type == \"Youtube video or playlist\":\n",
        "      hours, minutes, seconds = map(int, timestamp.split(':'))\n",
        "      total_seconds = hours * 3600 + minutes * 60 + seconds\n",
        "      return f\"{timestamp} - {URL}&t={total_seconds}\"\n",
        "    else:\n",
        "      return f\"{timestamp}\"\n",
        "\n",
        "import concurrent.futures\n",
        "import time\n",
        "from deep_translator import GoogleTranslator\n",
        "\n",
        "def summarize(prompt):\n",
        "    completion = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[\n",
        "            {\"role\": \"system\", \"content\": \"\"},\n",
        "            {\"role\": \"user\", \"content\": summary_prompt + \" \" + prompt}\n",
        "            ],\n",
        "            max_tokens=4096\n",
        "    )\n",
        "    return completion.choices[0].message.content\n",
        "\n",
        "def process_and_summarize(text,chunk_size):\n",
        "    overlap_size = 20\n",
        "    texts = [text[i:i+chunk_size] for i in range(0, len(text), chunk_size - overlap_size)]\n",
        "    cleaned_texts, timestamp_ranges = extract_and_clean_timestamps(texts)\n",
        "    summaries = []\n",
        "\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=parallel_api_calls) as executor:\n",
        "        future_to_chunk = {executor.submit(summarize, text_chunk): idx for idx, text_chunk in enumerate(cleaned_texts)}\n",
        "        for future in concurrent.futures.as_completed(future_to_chunk):\n",
        "            idx = future_to_chunk[future]\n",
        "            try:\n",
        "                summarized_chunk = future.result()\n",
        "                summary_piece = format_timestamp_link(timestamp_ranges[idx]) + \" \" + summarized_chunk\n",
        "                summary_piece += \"\\n\"\n",
        "                summaries.append((idx, summary_piece))\n",
        "            except Exception as exc:\n",
        "                print(f'Chunk {idx} generated an exception: {exc}')\n",
        "                # Resubmit the task with the new model\n",
        "                time.sleep(10)\n",
        "                future_to_chunk[executor.submit(summarize, texts[idx])] = idx\n",
        "\n",
        "    summaries.sort()  # Ensure summaries are in the correct order\n",
        "    final_summary =\"\"\n",
        "    if Translate_to != \"English\":\n",
        "      translated_summaries = []\n",
        "      for _,summary in summaries:\n",
        "        translated_summary = GoogleTranslator(source='auto', target=language_codes[Translate_to]).translate(summary)\n",
        "        translated_summaries.append(translated_summary)\n",
        "        final_summary += translated_summary + \"\\n\\n\"\n",
        "      final_summary = final_summary.strip()\n",
        "    else :\n",
        "      final_summary = \"\\n\\n\".join([summary for _, summary in summaries])\n",
        "\n",
        "    # Save the final summary\n",
        "    final_name = transcript_file_name.replace(\".md\", \"_FINAL_\"+str(chunk_size)+\".md\") if Type != \"Dropbox video link\" else \"final_dropbox_video.md\"\n",
        "    with open(final_name, 'w') as f:\n",
        "        f.write(final_summary)\n",
        "    return (final_summary)\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell # Unblock output\n",
        "InteractiveShell.ast_node_interactivity = \"all\"            # It starts to work after restart cell\n",
        "#%config InteractiveShell.ast_node_interactivity=\"all\"\n",
        "clear_output()\n",
        "print (\"Generating summary...\")\n",
        "general_summary = process_and_summarize(text,15000) # max string size = max_tokens x 4\n",
        "IPython.display.Markdown(\"\\n\\n **Short Summary:** \\n\\n\" + general_summary)\n",
        "final_summary = process_and_summarize(text,3072)\n",
        "clear_output()\n",
        "IPython.display.Markdown(\"\\n\\n **Short Summary:** \\n\\n\" + general_summary + \"\\n\\n\" + \"\\n\\n **Long Summary:** \\n\\n\" + final_summary )\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "cell_execution_strategy": "setup",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}