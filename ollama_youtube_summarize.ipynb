{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/theaidran/ollama_youtube_summarize/blob/main/ollama_youtube_summarize.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Put a YouTube link and hit Run a cell.\n",
        "Quick access to this colab notebook. [tinyurl.com/summarisation](https://tinyurl.com/summarisation)"
      ],
      "metadata": {
        "id": "WpJxh3ZmM25b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jwROe6WH2lZi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "16ab4c01-c158-406c-85c8-8d5e5e07874d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n\n **Short Summary:** \n\n00:00:00 - https://www.youtube.com/watch?v=t6VoqbAh9HM&t=0 **\"Building a Website with AI: A Step-by-Step Guide\"**\n\nThis video transcript excerpt provides a comprehensive guide on how to build a website using artificial intelligence (AI) tools. The speaker, who is creating a website that reviews camera drones, showcases several AI-powered tools such as Color Mind and Font Joy to help design the website's color scheme and font pairing.\n\nThe video begins with an overview of the website and its purpose: to compare and review camera drones to help consumers make informed decisions when purchasing. The speaker then uses Color Mind to generate a color scheme for the website, which is a crucial step in creating a visually appealing website.\n\nNext, the speaker uses Font Joy to generate font pairing options for the website. This tool suggests font combinations that can enhance the overall design of the website.\n\nThe video also explores the process of writing copy for the website using an AI-powered tool called Claud. The speaker provides a prompt and instructions to write a heading and subheading in the style of Alex Horoi and David Ogoli.\n\nFurthermore, the speaker demonstrates how to generate images for the website using mid-journey, a free online tool that can produce high-quality images based on user input. The video also covers how to use Canva to create featured images for blog posts.\n\nThroughout the video, the speaker highlights the benefits of using AI-powered tools in building a website, including time-saving, increased accuracy, and enhanced design options. Overall, this guide provides valuable insights and practical tips for anyone looking to build a website with AI assistance.\n\n\n00:11:15 - https://www.youtube.com/watch?v=t6VoqbAh9HM&t=675 **AI-Powered Featured Images: From Canva to a Professional Website**\n\nIn this conversation, we're continuing our discussion on building a website using AI tools. The speaker shows how to create a featured image using Canva and its AI features, such as Magic Media and background removers. They use these tools to generate images that match the style they want for their blog posts. Additionally, they highlight other AI tools used in this process, including font pairing, color schemes, and copywriting assistance from ChatGPT or Claude. The speaker also shares their experience with using Hostinger, Fontjoy, and Color Hunt to build a website, emphasizing the potential of AI in making the process faster and more efficient.\n\n\n\n\n **Long Summary:** \n\n00:00:00 - https://www.youtube.com/watch?v=t6VoqbAh9HM&t=0 **AI-Powered Website Building: A Game-Changer for Everyone**\n\nYou're continuing from where you left off, discussing AI-enabled tools that can help anyone get a website online quickly and easily without needing technical knowledge. You highlighted Reloom as one such tool, which uses AI to map out your entire website. You showed how to create a simple website using the free plan, and then generate content for each page using AI. With Reloom, you can build a comprehensive site map with individual sections for each page, and even get a rough idea of what each page could look like. This tool has the potential to democratize website creation, making it accessible to everyone regardless of their technical expertise.\n\n\n00:02:18 - https://www.youtube.com/watch?v=t6VoqbAh9HM&t=138 **Building Your Website with AI**\n\nSo, you're not starting from scratch anymore. Now it's time for hosting, and I recommend Hostinger, who happens to be sponsoring today's video. As a result, they've hooked you up with a deal! Head over to hostinger.com to get your website for as little as $2.99/month, plus two months free. What's cool about Hostinger is that it'll actually build your website for you using AI on WordPress. Let's go ahead and click \"Claim Deal\" and select the Business website builder plan because most of the AI tools are under this plan. We can then add this to our cart, choosing whichever option works best for us.\n\n\n00:04:34 - https://www.youtube.com/watch?v=t6VoqbAh9HM&t=274 **AI-Powered Design Inspiration**\n\nWe continue exploring AI-powered design tools, this time diving into Colormind and Font Joy. We start by generating a random color palette on Colormind, and then lock in the colors that resonate with us. From there, we explore how to apply these colors to our website's style section.\n\nNext, we jump into Font Joy, an AI-powered font discovery tool. We generate various font styles until we find the perfect ones that complement our chosen color palette. In this case, we settle on the Roboto Condensed and Work Sans fonts.\n\nWe conclude by selecting these fonts in our website's style section, using them for headers and subheadings. This video demonstrates how AI can help designers discover design inspiration, streamline their workflow, and create visually appealing websites.\n\n\n00:06:48 - https://www.youtube.com/watch?v=t6VoqbAh9HM&t=408 **Building a Website: Filling in Content with AI Help**\n\nThe conversation continues as the speaker discusses using AI tools, specifically ChatGPT or Claude, to generate content for their website. They explain that the goal is to create a prompt that gets the desired style of writing, and then use it to write a header and subheader in the style of Alex Horoi and David Ogoli. The speaker shares their experience with generating the heading and subheading using ChatGPT, which resulted in a clear and informative summary that can be used for their website's content.\n\n\n00:09:01 - https://www.youtube.com/watch?v=t6VoqbAh9HM&t=541 **Creating Relevant Images for Website Content**\n\nThe video transcript excerpt continues with the creator discussing how to generate relevant images for website content. The speaker mentions using a DJI Mavic 2 camera drone to capture high-quality images and also explores alternative tools such as Mid Journey, Dolly 3, and Bing.com's image generation capabilities. The process involves tweaking settings, waiting for the images to generate, and replacing them on the website. The creator also recommends using Canva to add text, remove backgrounds, and enhance featured images for blog posts.\n\n\n00:11:27 - https://www.youtube.com/watch?v=t6VoqbAh9HM&t=687 **Consistent Branding Through Custom Featured Images**\n\nThe conversation continues with discussing the importance of consistent branding through custom featured images. The speaker highlights the benefits of using Magic Media's built-in image generator in Canva to create a unified style for every blog post. They demonstrate how to use this feature, generating several images, and then select one that fits their needs. The speaker also shares how to remove the background from an existing image using Canva's AI-powered background remover, which is only available in the paid version of the software. Additionally, they discuss adding a white outline around themselves in the image to make it stand out and finally, they wrap up by suggesting using the Robotto Condensed font style for their text.\n\n\n00:13:31 - https://www.youtube.com/watch?v=t6VoqbAh9HM&t=811 **Building a Website with AI: The Future of Web Development**\n\nThe summary continues as if we're already in the middle of a conversation:\n\n...and now we've got a pretty quickly made featured image using Canva and various AI features. We download this image as a JPEG, jump back over to our website, change out our featured image to the one we just created, and resize it a little bit so it uses the full image. There's our featured image with the text from the blog post right here...\n\n\n00:15:55 - https://www.youtube.com/watch?v=t6VoqbAh9HM&t=955 **Stay in the Loop with AI News and Tools**\n\nThe speaker continues to share a recent discovery, encouraging viewers to check out Future Tools, where they curate the coolest AI tools and update it almost daily. They also offer a free newsletter that shares only the most important news and tool recommendations. As an added incentive, the speaker will be giving away an Insta 360 X4 camera each month to subscribers of their YouTube channel and newsletter, starting from this point on.\n"
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# @title  { run: \"auto\", display-mode: \"form\" }\n",
        "# All credits to https://github.com/martinopiaggi/summarize\n",
        "# Good to see links:\n",
        "# https://github.com/hsiehjackson/RULER\n",
        "# https://ollama.com/library\n",
        "# https://amgadhasan.substack.com/p/sota-asr-tooling-long-form-transcription\n",
        "\n",
        "\n",
        "#1 Choose source url\n",
        "Link = \"https://www.youtube.com/watch?v=t6VoqbAh9HM\" #@param {type:\"string\"}\n",
        "Type_of_source = \"Youtube video or playlist\" #@param ['Youtube video or playlist', 'Google Drive video link','Dropbox video link', 'Local file']\n",
        "Type = Type_of_source\n",
        "URL = Link\n",
        "Translate_to = \"English\" # @param ['Afrikaans', 'Albanian', 'Amharic', 'Arabic', 'Armenian', 'Azerbaijani', 'Basque', 'Belarusian', 'Bengali', 'Bosnian', 'Bulgarian', 'Catalan', 'Cebuano', 'Chinese (Simplified)', 'Chinese (Traditional)', 'Corsican', 'Croatian', 'Czech', 'Danish', 'Dutch', 'English', 'Esperanto', 'Estonian', 'Finnish', 'French', 'Frisian', 'Galician', 'Georgian', 'German', 'Greek', 'Gujarati', 'Haitian Creole', 'Hausa', 'Hawaiian', 'Hebrew', 'Hindi', 'Hmong', 'Hungarian', 'Icelandic', 'Igbo', 'Indonesian', 'Irish', 'Italian', 'Japanese', 'Javanese', 'Kannada', 'Kazakh', 'Khmer', 'Korean', 'Kurdish', 'Kyrgyz', 'Lao', 'Latin', 'Latvian', 'Lithuanian', 'Luxembourgish', 'Macedonian', 'Malagasy', 'Malay', 'Malayalam', 'Maltese', 'Maori', 'Marathi', 'Mongolian', 'Myanmar (Burmese)', 'Nepali', 'Norwegian', 'Nyanja (Chichewa)', 'Pashto', 'Persian', 'Polish', 'Portuguese (Portugal, Brazil)', 'Punjabi', 'Romanian', 'Russian', 'Samoan', 'Scots Gaelic', 'Serbian', 'Sesotho', 'Shona', 'Sindhi', 'Sinhala (Sinhalese)', 'Slovak', 'Slovenian', 'Somali', 'Spanish', 'Sundanese', 'Swahili', 'Swedish', 'Tagalog (Filipino)', 'Tajik', 'Tamil', 'Telugu', 'Thai', 'Turkish', 'Ukrainian', 'Urdu', 'Uzbek', 'Vietnamese', 'Welsh', 'Xhosa', 'Yiddish', 'Yoruba', 'Zulu']\n",
        "\n",
        "language_codes = {'Afrikaans': 'af', 'Albanian': 'sq', 'Amharic': 'am', 'Arabic': 'ar', 'Armenian': 'hy', 'Azerbaijani': 'az', 'Basque': 'eu', 'Belarusian': 'be', 'Bengali': 'bn', 'Bosnian': 'bs', 'Bulgarian': 'bg', 'Catalan': 'ca', 'Cebuano': 'ceb', 'Chinese (Simplified)': 'zh-CN', 'Chinese (Traditional)': 'zh-TW', 'Corsican': 'co', 'Croatian': 'hr', 'Czech': 'cs', 'Danish': 'da', 'Dutch': 'nl', 'English': 'en', 'Esperanto': 'eo', 'Estonian': 'et', 'Finnish': 'fi', 'French': 'fr', 'Frisian': 'fy', 'Galician': 'gl', 'Georgian': 'ka', 'German': 'de', 'Greek': 'el', 'Gujarati': 'gu', 'Haitian Creole': 'ht', 'Hausa': 'ha', 'Hawaiian': 'haw', 'Hebrew': 'iw', 'Hindi': 'hi', 'Hmong': 'hmn', 'Hungarian': 'hu', 'Icelandic': 'is', 'Igbo': 'ig', 'Indonesian': 'id', 'Irish': 'ga', 'Italian': 'it', 'Japanese': 'ja', 'Javanese': 'jw', 'Kannada': 'kn', 'Kazakh': 'kk', 'Khmer': 'km', 'Korean': 'ko', 'Kurdish': 'ku', 'Kyrgyz': 'ky', 'Lao': 'lo', 'Latin': 'la', 'Latvian': 'lv', 'Lithuanian': 'lt', 'Luxembourgish': 'lb', 'Macedonian': 'mk', 'Malagasy': 'mg', 'Malay': 'ms', 'Malayalam': 'ml', 'Maltese': 'mt', 'Maori': 'mi', 'Marathi': 'mr', 'Mongolian': 'mn', 'Myanmar (Burmese)': 'my', 'Nepali': 'ne', 'Norwegian': 'no', 'Nyanja (Chichewa)': 'ny', 'Pashto': 'ps', 'Persian': 'fa', 'Polish': 'pl', 'Portuguese (Portugal, Brazil)': 'pt', 'Punjabi': 'pa', 'Romanian': 'ro', 'Russian': 'ru', 'Samoan': 'sm', 'Scots Gaelic': 'gd', 'Serbian': 'sr', 'Sesotho': 'st', 'Shona': 'sn', 'Sindhi': 'sd', 'Sinhala (Sinhalese)': 'si', 'Slovak': 'sk', 'Slovenian': 'sl', 'Somali': 'so', 'Spanish': 'es', 'Sundanese': 'su', 'Swahili': 'sw', 'Swedish': 'sv', 'Tagalog (Filipino)': 'tl', 'Tajik': 'tg', 'Tamil': 'ta', 'Telugu': 'te', 'Thai': 'th', 'Turkish': 'tr', 'Ukrainian': 'uk', 'Urdu': 'ur', 'Uzbek': 'uz', 'Vietnamese': 'vi', 'Welsh': 'cy', 'Xhosa': 'xh', 'Yiddish': 'yi', 'Yoruba': 'yo', 'Zulu': 'zu'}\n",
        "\n",
        "#@markdown ---\n",
        "#markdown Insert your API key depending on which endpoint you want to use\n",
        "# API Configuration\n",
        "api_key = \"ollama\"\n",
        "api_endpoint = \"Custom\"\n",
        "ollama_model = \"llama3\" # param ['llama3', 'phi3', 'vicuna:13b-v1.5-16k-q4_0']\n",
        "\n",
        "endpoints = {\n",
        "    \"Groq\": \"https://api.groq.com/openai/v1\",\n",
        "    \"OpenAI\": \"https://api.openai.com/v1\",\n",
        "    \"Custom\": \"http://localhost:11434/v1\"  # ollama endpoint\n",
        "}\n",
        "base_url = endpoints.get(api_endpoint)\n",
        "\n",
        "models = {\n",
        "    \"Groq\": \"llama3-8b-8192\",\n",
        "    \"OpenAI\": \"gpt-3.5-turbo\",\n",
        "    \"Custom\": ollama_model  # Placeholder for any custlom model\n",
        "}\n",
        "model = models.get(api_endpoint)\n",
        "\n",
        "use_Youtube_captions = True #@param {type:\"boolean\"}\n",
        "# @markdown  * otherwise transcribe audio\n",
        "\n",
        "\n",
        "#2 launch ollama server with llama3\n",
        "try: # to faster next start\n",
        "  import pytube\n",
        "except ImportError:\n",
        "  !curl -fsSL https://ollama.com/install.sh | sh\n",
        "  !tmux new -d ollama serve\n",
        "  !ollama run {ollama_model} !\n",
        "\n",
        "\n",
        "#3 install libs: youtube and whisperx\n",
        "import subprocess\n",
        "import re\n",
        "import os\n",
        "import IPython\n",
        "from IPython.display import clear_output\n",
        "\n",
        "if use_Youtube_captions:\n",
        "  !pip install youtube-transcript-api\n",
        "  from youtube_transcript_api import YouTubeTranscriptApi\n",
        "\n",
        "if (not Type == \"Youtube video or playlist\") or (not use_Youtube_captions):\n",
        "  try:\n",
        "    import whisperx\n",
        "  except ImportError:\n",
        "    print(\"installing whisperx...may take a few minutes\")\n",
        "    !pip install git+https://github.com/m-bain/whisperx.git > /dev/null\n",
        "    clear_output()\n",
        "\n",
        "try:\n",
        "  import deep_translator\n",
        "except ImportError:\n",
        "  !pip install -U deep-translator\n",
        "\n",
        "try:\n",
        "  import openai\n",
        "except ImportError:\n",
        "  !pip install openai\n",
        "  #clear_output()\n",
        "\n",
        "import openai\n",
        "client = openai.OpenAI(api_key=api_key, base_url=base_url)\n",
        "\n",
        "if Type == \"Youtube video or playlist\":\n",
        "  try:\n",
        "    import pytube\n",
        "  except ImportError:\n",
        "    #!pip install git+https://github.com/pytube/pytube\n",
        "    !pip install git+https://github.com/metalshanked/pytube\n",
        "    #clear_output()\n",
        "    from pytube import YouTube\n",
        "\n",
        "if Type == \"Google Drive video link\":\n",
        "  from google.colab import drive\n",
        "  drive.mount('/gdrive')\n",
        "\n",
        "#4 Video fetching\n",
        "skip_transcription=False\n",
        "text = \"\"\n",
        "textTimestamps = \"\"\n",
        "\n",
        "def seconds_to_time_format(seconds):\n",
        "    hours, remainder = divmod(seconds, 3600)\n",
        "    minutes, seconds = divmod(remainder, 60)\n",
        "    return f\"{int(hours):02d}:{int(minutes):02d}:{int(seconds):02d}\"\n",
        "\n",
        "def download_youtube_audio_only(url):\n",
        "    yt = YouTube(url)\n",
        "    audio_stream = yt.streams.get_audio_only()\n",
        "    saved_path = audio_stream.download(output_path=\".\", skip_existing=True)\n",
        "    return saved_path\n",
        "\n",
        "def download_youtube_captions(url):\n",
        "    regex = r'(?:https?:\\/\\/)?(?:www\\.)?(?:youtube\\.com\\/(?:[^\\/\\n\\s]+\\/\\S+\\/|(?:v|e(?:mbed)?)\\/|\\S*?[?&]v=)|youtu\\.be\\/)([a-zA-Z0-9_-]{11})'\n",
        "    video_id =  re.search(regex, url).group(1)\n",
        "    transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\n",
        "\n",
        "    try:\n",
        "      transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=['en'])\n",
        "    except:\n",
        "      for available_transcript in transcript_list:\n",
        "        if available_transcript.is_translatable:\n",
        "          transcript = available_transcript.translate('en').fetch()\n",
        "          break\n",
        "\n",
        "    text = \"\"\n",
        "    for entry in transcript:\n",
        "            start_time = seconds_to_time_format(entry['start'])\n",
        "            text += f\"{start_time} {entry['text'].strip()}\\n\"\n",
        "\n",
        "    transcript_file_name = f\"{video_id}_captions.md\"\n",
        "\n",
        "    with open(transcript_file_name, 'w', encoding='utf-8') as f:\n",
        "      f.write(text)\n",
        "\n",
        "    return text,transcript_file_name\n",
        "\n",
        "if Type == \"Youtube video or playlist\":\n",
        "    #clean youtube url from timestamp\n",
        "    URL = re.sub('\\&t=\\d+s?', '', URL)\n",
        "    if use_Youtube_captions:\n",
        "      text, transcript_file_name = download_youtube_captions(URL)\n",
        "      skip_transcription=True\n",
        "    else:\n",
        "      video_path_local =  download_youtube_audio_only(URL)\n",
        "\n",
        "elif Type == \"Google Drive video link\":\n",
        "  subprocess.run(['ffmpeg', '-y', '-i', '/gdrive/My Drive/' + URL, '-vn', '-acodec', 'pcm_s16le',\n",
        "                  '-ar', '16000', '-ac', '1', 'gdrive_audio.wav'], check=True)\n",
        "  video_path_local = \"gdrive_audio.wav\"\n",
        "\n",
        "elif Type == \"Dropbox video link\":\n",
        "    subprocess.run(['wget', URL, '-O', 'dropbox_video.mp4'], check=True)\n",
        "    subprocess.run(['ffmpeg', '-y', '-i', 'dropbox_video.mp4', '-vn', '-acodec', 'pcm_s16le',\n",
        "                    '-ar', '16000', '-ac', '1', 'dropbox_video_audio.wav'], check=True)\n",
        "    video_path_local = \"dropbox_video_audio.wav\"\n",
        "\n",
        "elif Type == \"Local file\":\n",
        "    local_file_path = Source\n",
        "    subprocess.run(['ffmpeg', '-y', '-i', local_file_path, '-vn', '-acodec', 'pcm_s16le',\n",
        "                    '-ar', '16000', '-ac', '1', 'local_file_audio.wav'], check=True)\n",
        "    video_path_local = \"local_file_audio.wav\"\n",
        "\n",
        "\n",
        "#5 transcription using whisperx\n",
        "if not skip_transcription:\n",
        "  import whisperx\n",
        "  language = \"auto\" # param {type:\"string\"}\n",
        "  #initial_prompt = \"\" # @param {type:\"string\"}\n",
        "\n",
        "  asr_options={\"temperatures\": 0, \"beam_size\": 1, \"without_timestamps\": True,}\n",
        "  # Run on GPU with FP16\n",
        "  modelWhisperX = whisperx.load_model(\"large-v2\", device=\"cuda\", compute_type=\"float16\", asr_options=asr_options)\n",
        "\n",
        "  transcription = modelWhisperX.transcribe(str(video_path_local), batch_size=16,\n",
        "                                    language=None if language == \"auto\" else language,\n",
        "                                    task=\"translate\")\n",
        "\n",
        "  transcript_file_name = os.path.splitext(video_path_local)[0]+'.md'\n",
        "\n",
        "  with open(transcript_file_name, 'w') as f:\n",
        "    for segment in transcription[\"segments\"]:\n",
        "        start_time = seconds_to_time_format(segment['start'])\n",
        "        text += f\"{start_time} {segment['text'].strip()} \"\n",
        "\n",
        "    f.write(text)\n",
        "\n",
        "\n",
        "#6 Make a summary\n",
        "prompt_type = \"Summarization\"  # param ['Summarization', 'Only grammar correction with highlights']\n",
        "# markdown Set the number of parallel API calls (be mindful of usage rate limits)\n",
        "parallel_api_calls = 1 # param\n",
        "\n",
        "\n",
        "# Define your prompts using a dictionary for easier management\n",
        "prompts = {\n",
        "    'Summarization': \"\"\"Summarize the video transcript excerpt including a concise title that reflects the content. Wrap the title with **markdown bold notation**. Write the summary as if you are continuing a conversation without needing to signal a beginning. Here is the transcript: \"\"\",\n",
        "    'Only grammar correction with highlights': \"\"\"Repeat the following text correcting any grammatical errors and formatting error. Highlight only the important quote (if there are any) with **markdown bold notation**. Focus solely on the essence of the content as if you are continuing a conversation without using any form of introduction like 'Here's the corrected text:'. Here is the text to fix: \"\"\"\n",
        "}\n",
        "\n",
        "# Select the appropriate prompt\n",
        "summary_prompt = prompts[prompt_type]\n",
        "\n",
        "\n",
        "\n",
        "def extract_and_clean_timestamps(text_chunks):\n",
        "    timestamp_pattern = re.compile(r'(\\d{2}:\\d{2}:\\d{2})')\n",
        "    cleaned_texts = []\n",
        "    timestamp_ranges = []\n",
        "    for chunk in text_chunks:\n",
        "        timestamps = timestamp_pattern.findall(chunk)\n",
        "        if timestamps:\n",
        "            for timestamp in timestamps:\n",
        "                # Remove each found timestamp from the chunk\n",
        "                chunk = chunk.replace(timestamp, \"\")\n",
        "            timestamp_ranges.append(timestamps[0])  # Assuming you want the first timestamp per chunk\n",
        "        else:\n",
        "            timestamp_ranges.append(\"\")\n",
        "        cleaned_texts.append(chunk.strip())  # Strip to remove any leading/trailing whitespace\n",
        "    return cleaned_texts, timestamp_ranges\n",
        "\n",
        "def format_timestamp_link(timestamp):\n",
        "    if Type == \"Youtube video or playlist\":\n",
        "      hours, minutes, seconds = map(int, timestamp.split(':'))\n",
        "      total_seconds = hours * 3600 + minutes * 60 + seconds\n",
        "      return f\"{timestamp} - {URL}&t={total_seconds}\"\n",
        "    else:\n",
        "      return f\"{timestamp}\"\n",
        "\n",
        "import concurrent.futures\n",
        "import time\n",
        "from deep_translator import GoogleTranslator\n",
        "\n",
        "def summarize(prompt):\n",
        "    completion = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[\n",
        "            {\"role\": \"system\", \"content\": summary_prompt},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            max_tokens=4096\n",
        "    )\n",
        "    return completion.choices[0].message.content\n",
        "\n",
        "def process_and_summarize(text,chunk_size):\n",
        "    overlap_size = 20\n",
        "    texts = [text[i:i+chunk_size] for i in range(0, len(text), chunk_size - overlap_size)]\n",
        "    cleaned_texts, timestamp_ranges = extract_and_clean_timestamps(texts)\n",
        "    summaries = []\n",
        "\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=parallel_api_calls) as executor:\n",
        "        future_to_chunk = {executor.submit(summarize, text_chunk): idx for idx, text_chunk in enumerate(cleaned_texts)}\n",
        "        for future in concurrent.futures.as_completed(future_to_chunk):\n",
        "            idx = future_to_chunk[future]\n",
        "            try:\n",
        "                summarized_chunk = future.result()\n",
        "                summary_piece = format_timestamp_link(timestamp_ranges[idx]) + \" \" + summarized_chunk\n",
        "                summary_piece += \"\\n\"\n",
        "                summaries.append((idx, summary_piece))\n",
        "            except Exception as exc:\n",
        "                print(f'Chunk {idx} generated an exception: {exc}')\n",
        "                # Resubmit the task with the new model\n",
        "                time.sleep(10)\n",
        "                future_to_chunk[executor.submit(summarize, texts[idx])] = idx\n",
        "\n",
        "    summaries.sort()  # Ensure summaries are in the correct order\n",
        "    final_summary =\"\"\n",
        "    if Translate_to != \"English\":\n",
        "      translated_summaries = []\n",
        "      for _,summary in summaries:\n",
        "        translated_summary = GoogleTranslator(source='auto', target=language_codes[Translate_to]).translate(summary)\n",
        "        translated_summaries.append(translated_summary)\n",
        "        final_summary += translated_summary + \"\\n\\n\"\n",
        "      final_summary = final_summary.strip()\n",
        "    else :\n",
        "      final_summary = \"\\n\\n\".join([summary for _, summary in summaries])\n",
        "\n",
        "    # Save the final summary\n",
        "    final_name = transcript_file_name.replace(\".md\", \"_FINAL_\"+str(chunk_size)+\".md\") if Type != \"Dropbox video link\" else \"final_dropbox_video.md\"\n",
        "    with open(final_name, 'w') as f:\n",
        "        f.write(final_summary)\n",
        "    return (final_summary)\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell # Unblock output\n",
        "InteractiveShell.ast_node_interactivity = \"all\"            # It starts to work after restart cell\n",
        "#%config InteractiveShell.ast_node_interactivity=\"all\"\n",
        "clear_output()\n",
        "print (\"Generating summary...\")\n",
        "general_summary = process_and_summarize(text,15000) # max string size = max_tokens x 4\n",
        "IPython.display.Markdown(\"\\n\\n **Short Summary:** \\n\\n\" + general_summary)\n",
        "final_summary = process_and_summarize(text,3072)\n",
        "clear_output()\n",
        "IPython.display.Markdown(\"\\n\\n **Short Summary:** \\n\\n\" + general_summary + \"\\n\\n\" + \"\\n\\n **Long Summary:** \\n\\n\" + final_summary )\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}