{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/theaidran/ollama_youtube_summarize/blob/main/ollama_youtube_summarize.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title #####  Put a YouTube link below and hit Run a cell. Use any-language video and get any-language summary. Quick access to this colab notebook. [tinyurl.com/summarisation](https://tinyurl.com/summarisation) { display-mode: \"form\" }\n",
        "%config InteractiveShell.ast_node_interactivity=\"all\" #update python display config\n",
        "!pip install openai==1.55.3 > /dev/null\n",
        "!pip install httpx==0.27.2 > /dev/null\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "PddpLm1hdgvN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jwROe6WH2lZi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dc3b0431-4429-4f23-d20c-227f2f58a4b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n\n **Short Summary:** \n\n00:00:00 - https://www.youtube.com/watch?v=t6VoqbAh9HM&t=0 **AI-Generated Content Revolution: Leveraging ChatGPT, Claude, and Mid-Journey**\n\nIn this video transcript excerpt, a narrator discusses the capabilities of artificial intelligence (AI) in generating content for various purposes. The narrator demonstrates how to use AI tools such as ChatGPT and Claude to create website copies, images, and featured images for blog posts.\n\nThe segment begins with an introduction to the concept of using AI-generated content to revolutionize traditional methods of creating websites. The narrator explains that AI models like ChatGPT and Claude can be used to generate website copy that mirrors human writing styles, making it more convincing and engaging.\n\nTo create the website copy, the narrator provides a prompt to the AI models, detailing the site's purpose (reviewing drones) and asking for headings and subheadings in the style of well-known marketers like Alex Horoi and David Ogoli. The AI models generate the desired headings and subheadings, which are then copied and pasted onto the website.\n\nThe next section focuses on generating images using Mid-Journey, a tool that can create realistic images from text prompts. The narrator describes the process of creating an image of a camera drone flying over a city skyline, specifying settings such as model raw to achieve a more realistic result.\n\nFinally, the narrator discusses using Canva, a popular graphic design tool, to generate featured images for blog posts. The narrator explains that Canva allows users to easily add text, remove backgrounds, and manipulate images to create visually appealing graphics.\n\nThroughout the excerpt, the narrator emphasizes the importance of using AI-generated content to streamline website creation processes and reduce time spent on content development.\n\n\n00:11:15 - https://www.youtube.com/watch?v=t6VoqbAh9HM&t=675 **Building a Website with AI: A Quick Tour**\n\nAs we continue to explore the possibilities of building websites using AI, our narrator takes us on a whirlwind tour of Canva, an image creation tool. They start by creating a design and selecting the \"Magic Media\" option, which allows them to generate images or graphics. After experimenting with different styles and effects, they use Canva's built-in image generator to create some decent images.\n\nTheir goal is to create a featured image for their blog post, so they select one of the generated images and remove the background using AI. They then add text to the image, choosing a font that matches their website's style. With some quick adjustments, they've created a polished featured image.\n\nThe narrator continues to walk us through the process of building a website with AI, highlighting tools like Reloom for site mapping, Color Mind for color scheme selection, Font Joy for font pairing, ChatGPT or Claude for copywriting, and Mid Journey (or other image generators) for creating images. They even mention using Canva to create featured images for their blog posts.\n\nWhile the narrator acknowledges that AI isn't quite at the point where it can create a fully polished website on its own, they believe that with the right tools and some human involvement, it's possible to get really close.\n\n\n\n\n **Long Summary:** \n\n00:00:00 - https://www.youtube.com/watch?v=t6VoqbAh9HM&t=0 **Building a Website without Technical Knowledge with AI-Enabled Tools**\n\nAs we continue to explore, let's dive into an excerpt where the speaker shares their opinion on how having a website can be beneficial for everyone. They highlight the importance of having an online presence through platforms like blogs, digital storefronts, or course selling websites. The speaker then introduces AI-enabled tools that can help users get their website up and running quickly and easily, without requiring technical knowledge.\n\nOne such tool is Reloom, found at rom.io. With a free plan available forever to develop simple websites, this AI-powered tool maps out the entire website using natural language processing (NLP). By entering a prompt describing the website's purpose, users can generate a site map with pre-designed sections such as homepages, hero sections, feature lists, and more.\n\nIn the excerpt, the speaker demonstrates how to use Reloom by creating a website about drones and drone reviews. They enter a prompt describing their website's focus on reviewing camera drones for users deciding which is best for them. By clicking \"Generate Site Map,\" the tool starts building out a site map with individual sections, including homepages, hero sections, feature lists, call-to-actions, reviews, price comparisons, testimonials, FAQs, and footers.\n\nWith this sitemap in place, the speaker can click on specific sections to generate content using AI. This includes designing individual Pages like an about us page, review articles, and contact us pages. By scrolling up to the top and clicking \"Wireframe,\" users can even get a rough idea of what each Page could look like.\n\nLet's continue exploring how these AI-enabled tools can help individuals create their own websites without requiring extensive technical knowledge!\n\n\n00:02:18 - https://www.youtube.com/watch?v=t6VoqbAh9HM&t=138 **Automating Website Creation with AI**\n\nAs Matt Wolf continues, he emphasizes the importance of hosting in building a website. He recommends Hostinger as the most suitable option, especially for those who want to create their own website without starting from scratch. With Hostinger, users can get started at a low cost of $2.99 per month, and even enjoy two months free with their subscription. The tool also provides AI-powered website building capabilities on WordPress, which allows users to start creating their site in minutes.\n\nMatt then demonstrates how to create a website using the AI-based features offered by Hostinger. He chooses a business plan and selects the \"AI creates my website\" option. Once inside the hosting platform, he starts creating a new brand called Drone World, specifies the type of website (a Blog), enters a description, and lets AI do the work of setting up the site.\n\n\n00:04:34 - https://www.youtube.com/watch?v=t6VoqbAh9HM&t=274 **Designing with AI: Color Palettes and Fonts**\n\nAs the conversation continues, the speaker is showcasing how to create a color palette using Colormind, an AI-powered tool. They start by generating a random palette and like one of the colors, which they then lock in to generate more variations that match well with their design preferences. The speaker explains that this process allows them to experiment with different color combinations and ultimately creates a cohesive color scheme.\n\nWith their new color palette in place, the speaker moves on to selecting fonts using Font Joy, another AI-powered tool. They highlight how this site uses machine learning to determine which fonts pair well together and can recommend multiple options until they find one that suits their taste. In this case, they like the Robotto Condensed font for the main text and use it as the primary font on the website.\n\nThe speaker shares that with their color palette and font choices in place, they can now integrate these elements into their website design, selecting the correct font styles for headers, subheadings, and more.\n\n\n00:06:48 - https://www.youtube.com/watch?v=t6VoqbAh9HM&t=408 **Building a Website with AI-generated Content**\n\nAs the conversation continues, the speaker describes the process of creating a website using various tools. They have already selected a font pairing through Font Joy.com and settled on a color scheme using Color Mind's recommendations. With the bones of their website built on Hostinger, it's time to add some content. The speaker plans to use either Chat GPT or Claude to generate the needed text. Considering the AI models are quite similar for copywriting tasks, the choice between the two tools comes down to personal preference.\n\nTo create their desired style of writing, the speaker crafts a prompt that includes details about their website's purpose: reviewing and comparing drones to help consumers make informed decisions. They specify they need some website copies that will entice users to engage with the site, and provide additional instructions. The prompt is designed to generate content in the style of well-known marketers Alex Horoi and David Ogoli.\n\nThe AI tools are then asked to write a heading and subheading in the specified style, and the results are presented: \"The Ultimate Drone Buyer Guide - Soaring to New Heights with the Perfect UAV\" as the heading, and \"Discover the Best Drones for Your Needs and Budget: Expert Reviews, Side-by-Side Comparisons, and Insider Tips to Help You Make an Informed Decision\" as the subheading. The speaker is pleased with the generated content, highlighting the benefits of using AI tools in website development.\n\n\n00:09:01 - https://www.youtube.com/watch?v=t6VoqbAh9HM&t=541 **Optimizing Website Images and Featured Blog Post Visuals**\n\nShe goes on to demonstrate how to optimize website images, specifically by creating custom images for each section of the website. She suggests repeating this process for each section, making sure to include relevant images that align with the content. To generate more images, she recommends using tools like Mid Journey (with a small fee) or Dolly 3 (available for free on Bing.com), which has recently opened up its image generation capabilities without requiring Discord.\n\nShe uses the DJI Mavic 2 to create an image of a city skyline from her own camera drone, experimenting with settings and submitting the request. Once the images are generated, she clicks on one that looks like a real image and downloads it, then replaces an existing image on her website with the new one, centering it within the designated area.\n\nFinally, she mentions using Canva, her favorite tool for creating featured images for blog posts, as it's easy to use and allows users to add text, remove backgrounds, and manipulate elements. She suggests starting a design from scratch in Canva, specifically targeting YouTube thumbnails that tend to be visually appealing.\n\n\n00:11:27 - https://www.youtube.com/watch?v=t6VoqbAh9HM&t=687 **Creating Consistent Featured Images in Canva**\n\nAs we continue, we're exploring ways to create consistent featured images for blog posts using Canva. The creator suggests bypassing templates and instead utilizing Magic Media's built-in image generator. They demonstrate how to generate images, choosing the \"filmic\" style and a camera drone flying above a city skyline. After generating some decent-looking images, they select one and set it as the background for their featured image. Next, they open their own uploads in Canva and choose an image of themselves pointing. To remove the background from this image, they use Canva's AI-powered \"Background Remover\" tool (available in the paid version).\n\n\n00:13:31 - https://www.youtube.com/watch?v=t6VoqbAh9HM&t=811 **Building a Website with AI in Minutes**\n\nThe speaker is continuing to showcase the ease of building a website using artificial intelligence (AI) tools. They've quickly created a featured image using Canva, adding effects such as a light drop shadow to make it \"pop off the screen\". They then resize the image and tweak it to their liking.\n\nMeanwhile, they're highlighting the various AI tools used to build the website, including Reloom for sitemap planning, Hostinger with coupon code Matt wolf for fast setup, Color Mind for color schemes, Font Joy for font pairings, and either Chat GPT or Claude for copywriting. They've also generated images using Mid Journey, Leonardo, Dolly 3, or Bing Co-pilot.\n\nThe speaker notes that while AI can get close to producing a polished website, it's not quite there yet, but with some extra effort and tweaking, you can \"get pretty dang close\" to creating a professional-looking site. They emphasize the importance of experimentation and iteration to achieve the desired result.\n\n\n00:15:55 - https://www.youtube.com/watch?v=t6VoqbAh9HM&t=955 **Stay Ahead of the Game: AI Tools and Free Giveaways**\n\nThe host summarizes the benefits of checking out Future Tools, a platform that curates the coolest AI tools and provides updates on the latest AI news. By subscribing to the free newsletter and joining the YouTube channel, viewers can gain access to exclusive giveaways every month. The host is giving away an Insta 360 X4 camera this month, with future months featuring other cool gadgets. The host encourages viewers to share the video with others who might be interested in building a website or starting their own online project.\n"
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# @title  Summarize { run: \"auto\", display-mode: \"form\" }\n",
        "# All credits to https://github.com/martinopiaggi/summarize\n",
        "# Good to see links:\n",
        "# https://github.com/hsiehjackson/RULER\n",
        "# https://ollama.com/library\n",
        "# https://amgadhasan.substack.com/p/sota-asr-tooling-long-form-transcription\n",
        "\n",
        "\n",
        "#1 Choose source url\n",
        "Link = \"https://www.youtube.com/watch?v=t6VoqbAh9HM\" #@param {type:\"string\"}\n",
        "Type_of_source = \"Youtube video or playlist\" #@param ['Youtube video or playlist', 'Google Drive video link','Dropbox video link', 'Local file']\n",
        "Type = Type_of_source\n",
        "URL = Link\n",
        "Translate_to = \"English\" # @param ['Afrikaans', 'Albanian', 'Amharic', 'Arabic', 'Armenian', 'Azerbaijani', 'Basque', 'Belarusian', 'Bengali', 'Bosnian', 'Bulgarian', 'Catalan', 'Cebuano', 'Chinese (Simplified)', 'Chinese (Traditional)', 'Corsican', 'Croatian', 'Czech', 'Danish', 'Dutch', 'English', 'Esperanto', 'Estonian', 'Finnish', 'French', 'Frisian', 'Galician', 'Georgian', 'German', 'Greek', 'Gujarati', 'Haitian Creole', 'Hausa', 'Hawaiian', 'Hebrew', 'Hindi', 'Hmong', 'Hungarian', 'Icelandic', 'Igbo', 'Indonesian', 'Irish', 'Italian', 'Japanese', 'Javanese', 'Kannada', 'Kazakh', 'Khmer', 'Korean', 'Kurdish', 'Kyrgyz', 'Lao', 'Latin', 'Latvian', 'Lithuanian', 'Luxembourgish', 'Macedonian', 'Malagasy', 'Malay', 'Malayalam', 'Maltese', 'Maori', 'Marathi', 'Mongolian', 'Myanmar (Burmese)', 'Nepali', 'Norwegian', 'Nyanja (Chichewa)', 'Pashto', 'Persian', 'Polish', 'Portuguese (Portugal, Brazil)', 'Punjabi', 'Romanian', 'Russian', 'Samoan', 'Scots Gaelic', 'Serbian', 'Sesotho', 'Shona', 'Sindhi', 'Sinhala (Sinhalese)', 'Slovak', 'Slovenian', 'Somali', 'Spanish', 'Sundanese', 'Swahili', 'Swedish', 'Tagalog (Filipino)', 'Tajik', 'Tamil', 'Telugu', 'Thai', 'Turkish', 'Ukrainian', 'Urdu', 'Uzbek', 'Vietnamese', 'Welsh', 'Xhosa', 'Yiddish', 'Yoruba', 'Zulu']\n",
        "\n",
        "language_codes = {'Afrikaans': 'af', 'Albanian': 'sq', 'Amharic': 'am', 'Arabic': 'ar', 'Armenian': 'hy', 'Azerbaijani': 'az', 'Basque': 'eu', 'Belarusian': 'be', 'Bengali': 'bn', 'Bosnian': 'bs', 'Bulgarian': 'bg', 'Catalan': 'ca', 'Cebuano': 'ceb', 'Chinese (Simplified)': 'zh-CN', 'Chinese (Traditional)': 'zh-TW', 'Corsican': 'co', 'Croatian': 'hr', 'Czech': 'cs', 'Danish': 'da', 'Dutch': 'nl', 'English': 'en', 'Esperanto': 'eo', 'Estonian': 'et', 'Finnish': 'fi', 'French': 'fr', 'Frisian': 'fy', 'Galician': 'gl', 'Georgian': 'ka', 'German': 'de', 'Greek': 'el', 'Gujarati': 'gu', 'Haitian Creole': 'ht', 'Hausa': 'ha', 'Hawaiian': 'haw', 'Hebrew': 'iw', 'Hindi': 'hi', 'Hmong': 'hmn', 'Hungarian': 'hu', 'Icelandic': 'is', 'Igbo': 'ig', 'Indonesian': 'id', 'Irish': 'ga', 'Italian': 'it', 'Japanese': 'ja', 'Javanese': 'jw', 'Kannada': 'kn', 'Kazakh': 'kk', 'Khmer': 'km', 'Korean': 'ko', 'Kurdish': 'ku', 'Kyrgyz': 'ky', 'Lao': 'lo', 'Latin': 'la', 'Latvian': 'lv', 'Lithuanian': 'lt', 'Luxembourgish': 'lb', 'Macedonian': 'mk', 'Malagasy': 'mg', 'Malay': 'ms', 'Malayalam': 'ml', 'Maltese': 'mt', 'Maori': 'mi', 'Marathi': 'mr', 'Mongolian': 'mn', 'Myanmar (Burmese)': 'my', 'Nepali': 'ne', 'Norwegian': 'no', 'Nyanja (Chichewa)': 'ny', 'Pashto': 'ps', 'Persian': 'fa', 'Polish': 'pl', 'Portuguese (Portugal, Brazil)': 'pt', 'Punjabi': 'pa', 'Romanian': 'ro', 'Russian': 'ru', 'Samoan': 'sm', 'Scots Gaelic': 'gd', 'Serbian': 'sr', 'Sesotho': 'st', 'Shona': 'sn', 'Sindhi': 'sd', 'Sinhala (Sinhalese)': 'si', 'Slovak': 'sk', 'Slovenian': 'sl', 'Somali': 'so', 'Spanish': 'es', 'Sundanese': 'su', 'Swahili': 'sw', 'Swedish': 'sv', 'Tagalog (Filipino)': 'tl', 'Tajik': 'tg', 'Tamil': 'ta', 'Telugu': 'te', 'Thai': 'th', 'Turkish': 'tr', 'Ukrainian': 'uk', 'Urdu': 'ur', 'Uzbek': 'uz', 'Vietnamese': 'vi', 'Welsh': 'cy', 'Xhosa': 'xh', 'Yiddish': 'yi', 'Yoruba': 'yo', 'Zulu': 'zu'}\n",
        "\n",
        "#@markdown ---\n",
        "#markdown Insert your API key depending on which endpoint you want to use\n",
        "# API Configuration\n",
        "api_key = \"ollama\"\n",
        "api_endpoint = \"Custom\"\n",
        "ollama_model = \"llama3\" # param ['llama3', 'phi3', 'vicuna:13b-v1.5-16k-q4_0']\n",
        "\n",
        "endpoints = {\n",
        "    \"Groq\": \"https://api.groq.com/openai/v1\",\n",
        "    \"OpenAI\": \"https://api.openai.com/v1\",\n",
        "    \"Custom\": \"http://localhost:11434/v1\"  # ollama endpoint\n",
        "}\n",
        "base_url = endpoints.get(api_endpoint)\n",
        "\n",
        "models = {\n",
        "    \"Groq\": \"llama3-8b-8192\",\n",
        "    \"OpenAI\": \"gpt-3.5-turbo\",\n",
        "    \"Custom\": ollama_model  # Placeholder for any custlom model\n",
        "}\n",
        "model = models.get(api_endpoint)\n",
        "\n",
        "use_Youtube_captions = True #@param {type:\"boolean\"}\n",
        "# @markdown  * otherwise transcribe audio\n",
        "\n",
        "\n",
        "#2 launch ollama server with llama3\n",
        "try: # to faster next start\n",
        "  import pytubefix\n",
        "except ImportError:\n",
        "  !curl -fsSL https://ollama.com/install.sh | sh\n",
        "  !tmux new -d ollama serve\n",
        "  !ollama run {ollama_model} !\n",
        "\n",
        "\n",
        "#3 install libs: youtube and whisperx\n",
        "import subprocess\n",
        "import re\n",
        "import os\n",
        "import IPython\n",
        "from IPython.display import clear_output\n",
        "\n",
        "def install_whisperx():\n",
        "    try:\n",
        "      import whisperx\n",
        "    except ImportError:\n",
        "      print(\"installing whisperx...may take a few minutes\")\n",
        "      !pip uninstall torch torchvision torchaudio -y\n",
        "\n",
        "      # Workaround from: https://github.com/m-bain/whisperX/issues/1027#issuecomment-2627525081\n",
        "      !pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu121\n",
        "\n",
        "      # WhisperX-related packages:\n",
        "      !pip install ctranslate2==4.4.0\n",
        "      !pip install faster-whisper==1.1.0 > /dev/null\n",
        "      # !pip install git+https://github.com/m-bain/whisperx.git\n",
        "      !pip install whisperx==3.3.1 > /dev/null\n",
        "\n",
        "      !apt-get update\n",
        "      !apt-get install libcudnn8=8.9.2.26-1+cuda12.1\n",
        "      !apt-get install libcudnn8-dev=8.9.2.26-1+cuda12.1\n",
        "\n",
        "      !python -c \"import torch; torch.backends.cuda.matmul.allow_tf32 = True; torch.backends.cudnn.allow_tf32 = True\"\n",
        "      clear_output()\n",
        "\n",
        "if use_Youtube_captions:\n",
        "  !pip install youtube-transcript-api\n",
        "  from youtube_transcript_api import YouTubeTranscriptApi\n",
        "\n",
        "if (not Type == \"Youtube video or playlist\") or (not use_Youtube_captions):\n",
        "  install_whisperx()\n",
        "\n",
        "try:\n",
        "  import deep_translator\n",
        "except ImportError:\n",
        "  !pip install -U deep-translator\n",
        "\n",
        "try:\n",
        "  import openai\n",
        "except ImportError:\n",
        "  !pip install openai==1.55.3\n",
        "  !pip install httpx==0.27.2  #clear_output()\n",
        "\n",
        "import openai\n",
        "client = openai.OpenAI(api_key=api_key, base_url=base_url)\n",
        "\n",
        "if Type == \"Youtube video or playlist\":\n",
        "  try:\n",
        "    import pytubefix\n",
        "  except ImportError:\n",
        "    #!pip install git+https://github.com/pytube/pytube\n",
        "    !pip install git+https://github.com/JuanBindez/pytubefix\n",
        "    #clear_output()\n",
        "    from pytubefix import YouTube\n",
        "\n",
        "if Type == \"Google Drive video link\":\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "#4 Video fetching\n",
        "skip_transcription=False\n",
        "text = \"\"\n",
        "textTimestamps = \"\"\n",
        "\n",
        "def seconds_to_time_format(seconds):\n",
        "    hours, remainder = divmod(seconds, 3600)\n",
        "    minutes, seconds = divmod(remainder, 60)\n",
        "    return f\"{int(hours):02d}:{int(minutes):02d}:{int(seconds):02d}\"\n",
        "\n",
        "def download_youtube_audio_only(url):\n",
        "    yt = YouTube(url)\n",
        "    audio_stream = yt.streams.get_audio_only()\n",
        "    saved_path = audio_stream.download(output_path=\".\", skip_existing=True)\n",
        "    return saved_path\n",
        "\n",
        "def check_if_captions_exist(url):\n",
        "    regex = r'(?:https?:\\/\\/)?(?:www\\.)?(?:youtube\\.com\\/(?:[^\\/\\n\\s]+\\/\\S+\\/|(?:v|e(?:mbed)?)\\/|\\S*?[?&]v=)|youtu\\.be\\/)([a-zA-Z0-9_-]{11})'\n",
        "    video_id =  re.search(regex, url).group(1)\n",
        "\n",
        "    try:\n",
        "      transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\n",
        "      return (True)\n",
        "    except:\n",
        "      return (False)\n",
        "\n",
        "def download_youtube_captions(url):\n",
        "    regex = r'(?:https?:\\/\\/)?(?:www\\.)?(?:youtube\\.com\\/(?:[^\\/\\n\\s]+\\/\\S+\\/|(?:v|e(?:mbed)?)\\/|\\S*?[?&]v=)|youtu\\.be\\/)([a-zA-Z0-9_-]{11})'\n",
        "    video_id =  re.search(regex, url).group(1)\n",
        "    transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\n",
        "\n",
        "    try:\n",
        "      transcript = YouTubeTranscriptApi.get_transcript(video_id) #languages=['en']\n",
        "    except:\n",
        "      for available_transcript in transcript_list:\n",
        "        if available_transcript.is_translatable:\n",
        "          transcript = available_transcript.translate('en').fetch()\n",
        "          break\n",
        "\n",
        "    text = \"\"\n",
        "    for entry in transcript:\n",
        "            start_time = seconds_to_time_format(entry['start'])\n",
        "            text += f\"{start_time} {entry['text'].strip()}\\n\"\n",
        "\n",
        "    transcript_file_name = f\"{video_id}_captions.md\"\n",
        "\n",
        "    with open(transcript_file_name, 'w', encoding='utf-8') as f:\n",
        "      f.write(text)\n",
        "\n",
        "    return text,transcript_file_name\n",
        "\n",
        "if Type == \"Youtube video or playlist\":\n",
        "    #clean youtube url from timestamp\n",
        "    URL = re.sub('\\&t=\\d+s?', '', URL)\n",
        "\n",
        "    if use_Youtube_captions and check_if_captions_exist(URL):\n",
        "      text, transcript_file_name = download_youtube_captions(URL)\n",
        "      skip_transcription=True\n",
        "    else:\n",
        "      install_whisperx()\n",
        "      video_path_local =  download_youtube_audio_only(URL)\n",
        "\n",
        "elif Type == \"Google Drive video link\":\n",
        "  subprocess.run(['ffmpeg', '-y', '-i', 'drive/MyDrive/' + URL, '-vn', '-acodec', 'pcm_s16le',\n",
        "                  '-ar', '16000', '-ac', '1', 'gdrive_audio.wav'], check=True)\n",
        "  video_path_local = \"gdrive_audio.wav\"\n",
        "\n",
        "elif Type == \"Dropbox video link\":\n",
        "    subprocess.run(['wget', URL, '-O', 'dropbox_video.mp4'], check=True)\n",
        "    subprocess.run(['ffmpeg', '-y', '-i', 'dropbox_video.mp4', '-vn', '-acodec', 'pcm_s16le',\n",
        "                    '-ar', '16000', '-ac', '1', 'dropbox_video_audio.wav'], check=True)\n",
        "    video_path_local = \"dropbox_video_audio.wav\"\n",
        "\n",
        "elif Type == \"Local file\":\n",
        "    local_file_path = Source\n",
        "    subprocess.run(['ffmpeg', '-y', '-i', local_file_path, '-vn', '-acodec', 'pcm_s16le',\n",
        "                    '-ar', '16000', '-ac', '1', 'local_file_audio.wav'], check=True)\n",
        "    video_path_local = \"local_file_audio.wav\"\n",
        "\n",
        "\n",
        "#5 transcription using whisperx\n",
        "if not skip_transcription:\n",
        "  import whisperx\n",
        "  language = \"auto\" # param {type:\"string\"}\n",
        "  #initial_prompt = \"\" # @param {type:\"string\"}\n",
        "\n",
        "  asr_options={\"temperatures\": 0, \"beam_size\": 1, \"without_timestamps\": True,}\n",
        "  # Run on GPU with FP16\n",
        "  modelWhisperX = whisperx.load_model(\"large-v2\", device=\"cuda\", compute_type=\"float16\", asr_options=asr_options)\n",
        "\n",
        "  transcription = modelWhisperX.transcribe(str(video_path_local), batch_size=16,\n",
        "                                    language=None if language == \"auto\" else language,\n",
        "                                    task=\"translate\")\n",
        "\n",
        "  transcript_file_name = os.path.splitext(video_path_local)[0]+'.md'\n",
        "\n",
        "  with open(transcript_file_name, 'w') as f:\n",
        "    for segment in transcription[\"segments\"]:\n",
        "        start_time = seconds_to_time_format(segment['start'])\n",
        "        text += f\"{start_time} {segment['text'].strip()} \"\n",
        "\n",
        "    f.write(text)\n",
        "\n",
        "\n",
        "#6 Make a summary\n",
        "prompt_type = \"Summarization\"  # param ['Summarization', 'Only grammar correction with highlights']\n",
        "# markdown Set the number of parallel API calls (be mindful of usage rate limits)\n",
        "parallel_api_calls = 1 # param\n",
        "\n",
        "\n",
        "# Define your prompts using a dictionary for easier management\n",
        "prompts = {\n",
        "    'Summarization': \"\"\"Summarize the video transcript excerpt, including a bold title. Use narration in third-person. Write the summary as if you are continuing a conversation without needing to signal a beginning. Here is the transcript: \"\"\",\n",
        "    'Only grammar correction with highlights': \"\"\"Repeat the following text correcting any grammatical errors and formatting error. Highlight only the important quote (if there are any) with **markdown bold notation**. Focus solely on the essence of the content as if you are continuing a conversation without using any form of introduction like 'Here's the corrected text:'. Here is the text to fix: \"\"\"\n",
        "}\n",
        "\n",
        "# Select the appropriate prompt\n",
        "summary_prompt = prompts[prompt_type]\n",
        "\n",
        "\n",
        "\n",
        "def extract_and_clean_timestamps(text_chunks):\n",
        "    timestamp_pattern = re.compile(r'(\\d{2}:\\d{2}:\\d{2})')\n",
        "    cleaned_texts = []\n",
        "    timestamp_ranges = []\n",
        "    for chunk in text_chunks:\n",
        "        timestamps = timestamp_pattern.findall(chunk)\n",
        "        if timestamps:\n",
        "            for timestamp in timestamps:\n",
        "                # Remove each found timestamp from the chunk\n",
        "                chunk = chunk.replace(timestamp, \"\")\n",
        "            timestamp_ranges.append(timestamps[0])  # Assuming you want the first timestamp per chunk\n",
        "        else:\n",
        "            timestamp_ranges.append(\"\")\n",
        "        cleaned_texts.append(chunk.strip())  # Strip to remove any leading/trailing whitespace\n",
        "    return cleaned_texts, timestamp_ranges\n",
        "\n",
        "def format_timestamp_link(timestamp):\n",
        "    if Type == \"Youtube video or playlist\":\n",
        "      hours, minutes, seconds = map(int, timestamp.split(':'))\n",
        "      total_seconds = hours * 3600 + minutes * 60 + seconds\n",
        "      return f\"{timestamp} - {URL}&t={total_seconds}\"\n",
        "    else:\n",
        "      return f\"{timestamp}\"\n",
        "\n",
        "import concurrent.futures\n",
        "import time\n",
        "from deep_translator import GoogleTranslator\n",
        "\n",
        "def summarize(prompt):\n",
        "    completion = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[\n",
        "            {\"role\": \"system\", \"content\": \"\"},\n",
        "            {\"role\": \"user\", \"content\": summary_prompt + \" \" + prompt}\n",
        "            ],\n",
        "            max_tokens=4096\n",
        "    )\n",
        "    return completion.choices[0].message.content\n",
        "\n",
        "def process_and_summarize(text,chunk_size):\n",
        "    overlap_size = 20\n",
        "    texts = [text[i:i+chunk_size] for i in range(0, len(text), chunk_size - overlap_size)]\n",
        "    cleaned_texts, timestamp_ranges = extract_and_clean_timestamps(texts)\n",
        "    summaries = []\n",
        "\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=parallel_api_calls) as executor:\n",
        "        future_to_chunk = {executor.submit(summarize, text_chunk): idx for idx, text_chunk in enumerate(cleaned_texts)}\n",
        "        for future in concurrent.futures.as_completed(future_to_chunk):\n",
        "            idx = future_to_chunk[future]\n",
        "            try:\n",
        "                summarized_chunk = future.result()\n",
        "                summary_piece = format_timestamp_link(timestamp_ranges[idx]) + \" \" + summarized_chunk\n",
        "                summary_piece += \"\\n\"\n",
        "                summaries.append((idx, summary_piece))\n",
        "            except Exception as exc:\n",
        "                print(f'Chunk {idx} generated an exception: {exc}')\n",
        "                # Resubmit the task with the new model\n",
        "                time.sleep(10)\n",
        "                future_to_chunk[executor.submit(summarize, texts[idx])] = idx\n",
        "\n",
        "    summaries.sort()  # Ensure summaries are in the correct order\n",
        "    final_summary =\"\"\n",
        "    if Translate_to != \"English\":\n",
        "      translated_summaries = []\n",
        "      for _,summary in summaries:\n",
        "        translated_summary = GoogleTranslator(source='auto', target=language_codes[Translate_to]).translate(summary)\n",
        "        translated_summaries.append(translated_summary)\n",
        "        final_summary += translated_summary + \"\\n\\n\"\n",
        "      final_summary = final_summary.strip()\n",
        "    else :\n",
        "      final_summary = \"\\n\\n\".join([summary for _, summary in summaries])\n",
        "\n",
        "    # Save the final summary\n",
        "    final_name = transcript_file_name.replace(\".md\", \"_FINAL_\"+str(chunk_size)+\".md\") if Type != \"Dropbox video link\" else \"final_dropbox_video.md\"\n",
        "    with open(final_name, 'w') as f:\n",
        "        f.write(final_summary)\n",
        "    return (final_summary)\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell # Unblock output\n",
        "InteractiveShell.ast_node_interactivity = \"all\"            # It starts to work after restart cell\n",
        "#%config InteractiveShell.ast_node_interactivity=\"all\"\n",
        "clear_output()\n",
        "print (\"Generating summary...\")\n",
        "general_summary = process_and_summarize(text,15000) # max string size = max_tokens x 4\n",
        "IPython.display.Markdown(\"\\n\\n **Short Summary:** \\n\\n\" + general_summary)\n",
        "final_summary = process_and_summarize(text,3072)\n",
        "clear_output()\n",
        "IPython.display.Markdown(\"\\n\\n **Short Summary:** \\n\\n\" + general_summary + \"\\n\\n\" + \"\\n\\n **Long Summary:** \\n\\n\" + final_summary )\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "cell_execution_strategy": "setup",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}