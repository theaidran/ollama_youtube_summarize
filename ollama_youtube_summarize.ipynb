{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/theaidran/ollama_youtube_summarize/blob/main/ollama_youtube_summarize.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Put a YouTube link and hit Run a cell.\n",
        "Quick access to this colab notebook. [tinyurl.com/summarisation](https://tinyurl.com/summarisation)"
      ],
      "metadata": {
        "id": "WpJxh3ZmM25b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "jwROe6WH2lZi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d19ee4fd-6532-48f5-d8e2-a142c4a4169f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n\n **Short Summary:** \n\n00:00:00 - https://www.youtube.com/watch?v=t6VoqbAh9HM&t=0 **AI-Powered Website Creation: A Step-by-Step Guide**\n\nThis video transcript excerpt provides a concise guide on how to create a website using AI-powered tools, specifically focusing on color scheme selection, font pairing, and content creation. The title that reflects the content is:\n\n**Automating Your Website's Design with ColorMind & FontJoy: A Beginner's Guide**\n\nThe article summarizes the steps taken by the creator:\n\n1. **Color Scheme Selection**: Using ColorMind, a free AI-powered tool, to generate a color palette and select a combination of colors for the website.\n2. **Font Pairing**: Utilizing FontJoy, another AI-powered tool, to pair fonts for headings and body text.\n3. **Content Creation**: Using Claud, an AI-powered writing tool, to generate copy for the website's heading, subheading, and possibly other sections.\n\nThe excerpt concludes by highlighting the importance of having relevant images on the website, suggesting popular camera drones flying above city skylines, and providing a brief overview of image generation tools like Mid Journey and Dolly 3.\n\n\n00:11:15 - https://www.youtube.com/watch?v=t6VoqbAh9HM&t=675 **Designing a Featured Image using Canva**\n\nThe video transcript excerpt discusses designing a featured image for a blog post or website using Canva, specifically creating a YouTube thumbnail. The speaker demonstrates how to use AI features in Canva to generate images, remove backgrounds, and add text and effects to create a professional-looking image.\n\n\n\n\n **Long Summary:** \n\n00:00:00 - https://www.youtube.com/watch?v=t6VoqbAh9HM&t=0 **AI-Powered Website Building Tools**\n\nThe speaker continues by highlighting Reloom, an AI-enabled tool that helps create a website without requiring technical knowledge. They demonstrate how to use Reloom to generate a site map for their drone review and comparison website. With just a few clicks, they're able to build out the site's structure, including individual pages like the homepage, about us page, reviews, and more. The AI technology generates content for each page, allowing the user to visualize the layout and design of the website in a wireframe format.\n\n\n00:02:18 - https://www.youtube.com/watch?v=t6VoqbAh9HM&t=138 **Building a Website with Hostinger**\n\nContinuing from where we left off, we're building a website with Hostinger, who sponsored today's video. We're going to use their Business website builder, which includes AI tools on WordPress. The plan costs as little as $2.99 a month, with two months free. With this plan, we'll be able to create a website in minutes using Hostinger's AI features.\n\n\n00:04:34 - https://www.youtube.com/watch?v=t6VoqbAh9HM&t=274 **Color Palette Generation with AI**\n\nContinuing from where we left off, it seems we've successfully used Colormind's AI-powered color palette generation tool to find a combination of colors that match well together. We liked the blue and locked it in, then generated more variations until we found a color scheme that we really like. Now that we have our colors dialed in, we can move on to finding some good fonts for our website using Fontjoy's AI-powered font generation tool.\n\n\n00:06:48 - https://www.youtube.com/watch?v=t6VoqbAh9HM&t=408 **Building a Website: From Font Pairings to Content Creation**\n\nThe summary continues from where we left off earlier. The speaker is now focused on creating content for their website, which reviews and compares drones. They're using AI tools like Claude or Chat GPT to generate content, with the goal of writing in a style similar to Alex Horoi or David Ogoli. The speaker shares their prompt with the AI tool, asking it to write a heading and subheading in those styles. The output is a heading \"The Ultimate Drone Buyer Guide: Reaching New Heights with the Perfect UAV\" and a subheading \"Discover the Best Drones for Your Needs and Budget: Expert Reviews, Side-by-Side Comparisons, and Insider Tips to Help You Make an Informed Decision.\"\n\n\n00:09:01 - https://www.youtube.com/watch?v=t6VoqbAh9HM&t=541 **Headings and Subheadings**\n\nThe video transcript excerpt discusses how to copy headings and subheadings from existing websites and replace them with the same content on your own website. The speaker also shares their experience using DJI Mavic 2 for images, but recommends other tools like Mid Journey and Dolly 3 for generating images. Additionally, they demonstrate how to create featured images for blog posts using Canva, a popular design tool.\n\n\n00:11:27 - https://www.youtube.com/watch?v=t6VoqbAh9HM&t=687 **Best Practices for Blog Featured Images**\n\nThe video discusses the importance of having a consistent style for featured images on blogs. The speaker suggests using Canva's Magic Media feature to generate images, specifically ones with a drone flying above a city skyline. They use a background remover tool to remove the background from their own uploaded image and add an outline around themselves. The resulting image has a professional-looking appearance. The video also touches on adding text to the image, using a specific font style (Robotto Condensed) that matches the website's design.\n\n\n00:13:31 - https://www.youtube.com/watch?v=t6VoqbAh9HM&t=811 **Building a Website with AI in Minutes!**\n\nThe summary continues: As we wrap up our website, I'll go ahead and save it as a featured image. We've used Canva and various AI features to create this pretty quickly made featured image. Using Canva's AI tools, we can even download this image as a JPEG.\n\n\n00:15:55 - https://www.youtube.com/watch?v=t6VoqbAh9HM&t=955 **Staying Ahead of the Curve: AI Tools and News**\n\nContinuing where we left off, the speaker shares that they curate a list of cool AI tools on their channel, Future Tools, which is updated almost daily. They also offer a free newsletter that sends subscribers just the coolest tools and most important news. To make it even more exciting, the speaker announces that they will be giving away an Insta 360 X4 camera every month to those who subscribe to the YouTube channel and join the free newsletter.\n"
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "# @title  { run: \"auto\", display-mode: \"form\" }\n",
        "# All credits to https://github.com/martinopiaggi/summarize\n",
        "# Good to see links:\n",
        "# https://github.com/hsiehjackson/RULER\n",
        "# https://ollama.com/library\n",
        "# https://amgadhasan.substack.com/p/sota-asr-tooling-long-form-transcription\n",
        "\n",
        "\n",
        "#1 Choose source url\n",
        "Link = \"https://www.youtube.com/watch?v=t6VoqbAh9HM\" #@param {type:\"string\"}\n",
        "Type_of_source = \"Youtube video or playlist\" #@param ['Youtube video or playlist', 'Google Drive video link','Dropbox video link', 'Local file']\n",
        "Type = Type_of_source\n",
        "URL = Link\n",
        "Translate_to = \"English\" # @param ['Afrikaans', 'Albanian', 'Amharic', 'Arabic', 'Armenian', 'Azerbaijani', 'Basque', 'Belarusian', 'Bengali', 'Bosnian', 'Bulgarian', 'Catalan', 'Cebuano', 'Chinese (Simplified)', 'Chinese (Traditional)', 'Corsican', 'Croatian', 'Czech', 'Danish', 'Dutch', 'English', 'Esperanto', 'Estonian', 'Finnish', 'French', 'Frisian', 'Galician', 'Georgian', 'German', 'Greek', 'Gujarati', 'Haitian Creole', 'Hausa', 'Hawaiian', 'Hebrew', 'Hindi', 'Hmong', 'Hungarian', 'Icelandic', 'Igbo', 'Indonesian', 'Irish', 'Italian', 'Japanese', 'Javanese', 'Kannada', 'Kazakh', 'Khmer', 'Korean', 'Kurdish', 'Kyrgyz', 'Lao', 'Latin', 'Latvian', 'Lithuanian', 'Luxembourgish', 'Macedonian', 'Malagasy', 'Malay', 'Malayalam', 'Maltese', 'Maori', 'Marathi', 'Mongolian', 'Myanmar (Burmese)', 'Nepali', 'Norwegian', 'Nyanja (Chichewa)', 'Pashto', 'Persian', 'Polish', 'Portuguese (Portugal, Brazil)', 'Punjabi', 'Romanian', 'Russian', 'Samoan', 'Scots Gaelic', 'Serbian', 'Sesotho', 'Shona', 'Sindhi', 'Sinhala (Sinhalese)', 'Slovak', 'Slovenian', 'Somali', 'Spanish', 'Sundanese', 'Swahili', 'Swedish', 'Tagalog (Filipino)', 'Tajik', 'Tamil', 'Telugu', 'Thai', 'Turkish', 'Ukrainian', 'Urdu', 'Uzbek', 'Vietnamese', 'Welsh', 'Xhosa', 'Yiddish', 'Yoruba', 'Zulu']\n",
        "\n",
        "language_codes = {'Afrikaans': 'af', 'Albanian': 'sq', 'Amharic': 'am', 'Arabic': 'ar', 'Armenian': 'hy', 'Azerbaijani': 'az', 'Basque': 'eu', 'Belarusian': 'be', 'Bengali': 'bn', 'Bosnian': 'bs', 'Bulgarian': 'bg', 'Catalan': 'ca', 'Cebuano': 'ceb', 'Chinese (Simplified)': 'zh-CN', 'Chinese (Traditional)': 'zh-TW', 'Corsican': 'co', 'Croatian': 'hr', 'Czech': 'cs', 'Danish': 'da', 'Dutch': 'nl', 'English': 'en', 'Esperanto': 'eo', 'Estonian': 'et', 'Finnish': 'fi', 'French': 'fr', 'Frisian': 'fy', 'Galician': 'gl', 'Georgian': 'ka', 'German': 'de', 'Greek': 'el', 'Gujarati': 'gu', 'Haitian Creole': 'ht', 'Hausa': 'ha', 'Hawaiian': 'haw', 'Hebrew': 'iw', 'Hindi': 'hi', 'Hmong': 'hmn', 'Hungarian': 'hu', 'Icelandic': 'is', 'Igbo': 'ig', 'Indonesian': 'id', 'Irish': 'ga', 'Italian': 'it', 'Japanese': 'ja', 'Javanese': 'jw', 'Kannada': 'kn', 'Kazakh': 'kk', 'Khmer': 'km', 'Korean': 'ko', 'Kurdish': 'ku', 'Kyrgyz': 'ky', 'Lao': 'lo', 'Latin': 'la', 'Latvian': 'lv', 'Lithuanian': 'lt', 'Luxembourgish': 'lb', 'Macedonian': 'mk', 'Malagasy': 'mg', 'Malay': 'ms', 'Malayalam': 'ml', 'Maltese': 'mt', 'Maori': 'mi', 'Marathi': 'mr', 'Mongolian': 'mn', 'Myanmar (Burmese)': 'my', 'Nepali': 'ne', 'Norwegian': 'no', 'Nyanja (Chichewa)': 'ny', 'Pashto': 'ps', 'Persian': 'fa', 'Polish': 'pl', 'Portuguese (Portugal, Brazil)': 'pt', 'Punjabi': 'pa', 'Romanian': 'ro', 'Russian': 'ru', 'Samoan': 'sm', 'Scots Gaelic': 'gd', 'Serbian': 'sr', 'Sesotho': 'st', 'Shona': 'sn', 'Sindhi': 'sd', 'Sinhala (Sinhalese)': 'si', 'Slovak': 'sk', 'Slovenian': 'sl', 'Somali': 'so', 'Spanish': 'es', 'Sundanese': 'su', 'Swahili': 'sw', 'Swedish': 'sv', 'Tagalog (Filipino)': 'tl', 'Tajik': 'tg', 'Tamil': 'ta', 'Telugu': 'te', 'Thai': 'th', 'Turkish': 'tr', 'Ukrainian': 'uk', 'Urdu': 'ur', 'Uzbek': 'uz', 'Vietnamese': 'vi', 'Welsh': 'cy', 'Xhosa': 'xh', 'Yiddish': 'yi', 'Yoruba': 'yo', 'Zulu': 'zu'}\n",
        "\n",
        "#@markdown ---\n",
        "#markdown Insert your API key depending on which endpoint you want to use\n",
        "# API Configuration\n",
        "api_key = \"ollama\"\n",
        "api_endpoint = \"Custom\"\n",
        "ollama_model = \"llama3\" # param ['llama3', 'phi3', 'vicuna:13b-v1.5-16k-q4_0']\n",
        "\n",
        "endpoints = {\n",
        "    \"Groq\": \"https://api.groq.com/openai/v1\",\n",
        "    \"OpenAI\": \"https://api.openai.com/v1\",\n",
        "    \"Custom\": \"http://localhost:11434/v1\"  # ollama endpoint\n",
        "}\n",
        "base_url = endpoints.get(api_endpoint)\n",
        "\n",
        "models = {\n",
        "    \"Groq\": \"llama3-8b-8192\",\n",
        "    \"OpenAI\": \"gpt-3.5-turbo\",\n",
        "    \"Custom\": ollama_model  # Placeholder for any custlom model\n",
        "}\n",
        "model = models.get(api_endpoint)\n",
        "\n",
        "use_Youtube_captions = True #@param {type:\"boolean\"}\n",
        "# @markdown  * otherwise transcribe audio\n",
        "\n",
        "\n",
        "#2 launch ollama server with llama3\n",
        "try: # to faster next start\n",
        "  import pytube\n",
        "except ImportError:\n",
        "  !curl -fsSL https://ollama.com/install.sh | sh\n",
        "  !tmux new -d ollama serve\n",
        "  !ollama run {ollama_model} !\n",
        "\n",
        "\n",
        "#3 install libs: youtube and whisperx\n",
        "import subprocess\n",
        "import re\n",
        "import os\n",
        "import IPython\n",
        "from IPython.display import clear_output\n",
        "\n",
        "if use_Youtube_captions:\n",
        "  !pip install youtube-transcript-api\n",
        "  from youtube_transcript_api import YouTubeTranscriptApi\n",
        "\n",
        "if (not Type == \"Youtube video or playlist\") or (not use_Youtube_captions):\n",
        "  try:\n",
        "    import whisperx\n",
        "  except ImportError:\n",
        "    !pip install git+https://github.com/m-bain/whisperx.git > /dev/null\n",
        "    #clear_output()\n",
        "\n",
        "try:\n",
        "  import deep_translator\n",
        "except ImportError:\n",
        "  !pip install -U deep-translator\n",
        "\n",
        "try:\n",
        "  import openai\n",
        "except ImportError:\n",
        "  !pip install openai\n",
        "  #clear_output()\n",
        "\n",
        "import openai\n",
        "client = openai.OpenAI(api_key=api_key, base_url=base_url)\n",
        "\n",
        "if Type == \"Youtube video or playlist\":\n",
        "  try:\n",
        "    import pytube\n",
        "  except ImportError:\n",
        "    #!pip install git+https://github.com/pytube/pytube\n",
        "    !pip install git+https://github.com/metalshanked/pytube\n",
        "    #clear_output()\n",
        "    from pytube import YouTube\n",
        "\n",
        "if Type == \"Google Drive video link\":\n",
        "  from google.colab import drive\n",
        "  drive.mount('/gdrive')\n",
        "\n",
        "#4 Video fetching\n",
        "skip_transcription=False\n",
        "text = \"\"\n",
        "textTimestamps = \"\"\n",
        "\n",
        "def seconds_to_time_format(seconds):\n",
        "    hours, remainder = divmod(seconds, 3600)\n",
        "    minutes, seconds = divmod(remainder, 60)\n",
        "    return f\"{int(hours):02d}:{int(minutes):02d}:{int(seconds):02d}\"\n",
        "\n",
        "def download_youtube_audio_only(url):\n",
        "    yt = YouTube(url)\n",
        "    audio_stream = yt.streams.get_audio_only()\n",
        "    saved_path = audio_stream.download(output_path=\".\", skip_existing=True)\n",
        "    return saved_path\n",
        "\n",
        "def download_youtube_captions(url):\n",
        "    regex = r'(?:https?:\\/\\/)?(?:www\\.)?(?:youtube\\.com\\/(?:[^\\/\\n\\s]+\\/\\S+\\/|(?:v|e(?:mbed)?)\\/|\\S*?[?&]v=)|youtu\\.be\\/)([a-zA-Z0-9_-]{11})'\n",
        "    video_id =  re.search(regex, url).group(1)\n",
        "    transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\n",
        "\n",
        "    try:\n",
        "      transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=['en'])\n",
        "    except:\n",
        "      for available_transcript in transcript_list:\n",
        "        if available_transcript.is_translatable:\n",
        "          transcript = available_transcript.translate('en').fetch()\n",
        "          break\n",
        "\n",
        "    text = \"\"\n",
        "    for entry in transcript:\n",
        "            start_time = seconds_to_time_format(entry['start'])\n",
        "            text += f\"{start_time} {entry['text'].strip()}\\n\"\n",
        "\n",
        "    transcript_file_name = f\"{video_id}_captions.md\"\n",
        "\n",
        "    with open(transcript_file_name, 'w', encoding='utf-8') as f:\n",
        "      f.write(text)\n",
        "\n",
        "    return text,transcript_file_name\n",
        "\n",
        "if Type == \"Youtube video or playlist\":\n",
        "    #clean youtube url from timestamp\n",
        "    URL = re.sub('\\&t=\\d+s?', '', URL)\n",
        "    if use_Youtube_captions:\n",
        "      text, transcript_file_name = download_youtube_captions(URL)\n",
        "      skip_transcription=True\n",
        "    else:\n",
        "      video_path_local =  download_youtube_audio_only(URL)\n",
        "\n",
        "elif Type == \"Google Drive video link\":\n",
        "  subprocess.run(['ffmpeg', '-y', '-i', '/gdrive/My Drive/' + URL, '-vn', '-acodec', 'pcm_s16le',\n",
        "                  '-ar', '16000', '-ac', '1', 'gdrive_audio.wav'], check=True)\n",
        "  video_path_local = \"gdrive_audio.wav\"\n",
        "\n",
        "elif Type == \"Dropbox video link\":\n",
        "    subprocess.run(['wget', URL, '-O', 'dropbox_video.mp4'], check=True)\n",
        "    subprocess.run(['ffmpeg', '-y', '-i', 'dropbox_video.mp4', '-vn', '-acodec', 'pcm_s16le',\n",
        "                    '-ar', '16000', '-ac', '1', 'dropbox_video_audio.wav'], check=True)\n",
        "    video_path_local = \"dropbox_video_audio.wav\"\n",
        "\n",
        "elif Type == \"Local file\":\n",
        "    local_file_path = Source\n",
        "    subprocess.run(['ffmpeg', '-y', '-i', local_file_path, '-vn', '-acodec', 'pcm_s16le',\n",
        "                    '-ar', '16000', '-ac', '1', 'local_file_audio.wav'], check=True)\n",
        "    video_path_local = \"local_file_audio.wav\"\n",
        "\n",
        "\n",
        "#5 transcription using whisperx\n",
        "if not skip_transcription:\n",
        "  import whisperx\n",
        "  language = \"auto\" # param {type:\"string\"}\n",
        "  #initial_prompt = \"\" # @param {type:\"string\"}\n",
        "\n",
        "  asr_options={\"temperatures\": 0, \"beam_size\": 1, \"without_timestamps\": True,}\n",
        "  # Run on GPU with FP16\n",
        "  modelWhisperX = whisperx.load_model(\"large-v2\", device=\"cuda\", compute_type=\"float16\", asr_options=asr_options)\n",
        "\n",
        "  transcription = modelWhisperX.transcribe(str(video_path_local), batch_size=16,\n",
        "                                    language=None if language == \"auto\" else language,\n",
        "                                    task=\"translate\")\n",
        "\n",
        "  transcript_file_name = os.path.splitext(video_path_local)[0]+'.md'\n",
        "\n",
        "  with open(transcript_file_name, 'w') as f:\n",
        "    for segment in transcription[\"segments\"]:\n",
        "        start_time = seconds_to_time_format(segment['start'])\n",
        "        text += f\"{start_time} {segment['text'].strip()} \"\n",
        "\n",
        "    f.write(text)\n",
        "\n",
        "\n",
        "#6 Make a summary\n",
        "prompt_type = \"Summarization\"  # param ['Summarization', 'Only grammar correction with highlights']\n",
        "# markdown Set the number of parallel API calls (be mindful of usage rate limits)\n",
        "parallel_api_calls = 1 # param\n",
        "\n",
        "\n",
        "# Define your prompts using a dictionary for easier management\n",
        "prompts = {\n",
        "    'Summarization': \"\"\"Summarize the video transcript excerpt including a concise title that reflects the content. Wrap the title with **markdown bold notation**. Write the summary as if you are continuing a conversation without needing to signal a beginning. Here is the transcript: \"\"\",\n",
        "    'Only grammar correction with highlights': \"\"\"Repeat the following text correcting any grammatical errors and formatting error. Highlight only the important quote (if there are any) with **markdown bold notation**. Focus solely on the essence of the content as if you are continuing a conversation without using any form of introduction like 'Here's the corrected text:'. Here is the text to fix: \"\"\"\n",
        "}\n",
        "\n",
        "# Select the appropriate prompt\n",
        "summary_prompt = prompts[prompt_type]\n",
        "\n",
        "\n",
        "\n",
        "def extract_and_clean_timestamps(text_chunks):\n",
        "    timestamp_pattern = re.compile(r'(\\d{2}:\\d{2}:\\d{2})')\n",
        "    cleaned_texts = []\n",
        "    timestamp_ranges = []\n",
        "    for chunk in text_chunks:\n",
        "        timestamps = timestamp_pattern.findall(chunk)\n",
        "        if timestamps:\n",
        "            for timestamp in timestamps:\n",
        "                # Remove each found timestamp from the chunk\n",
        "                chunk = chunk.replace(timestamp, \"\")\n",
        "            timestamp_ranges.append(timestamps[0])  # Assuming you want the first timestamp per chunk\n",
        "        else:\n",
        "            timestamp_ranges.append(\"\")\n",
        "        cleaned_texts.append(chunk.strip())  # Strip to remove any leading/trailing whitespace\n",
        "    return cleaned_texts, timestamp_ranges\n",
        "\n",
        "def format_timestamp_link(timestamp):\n",
        "    if Type == \"Youtube video or playlist\":\n",
        "      hours, minutes, seconds = map(int, timestamp.split(':'))\n",
        "      total_seconds = hours * 3600 + minutes * 60 + seconds\n",
        "      return f\"{timestamp} - {URL}&t={total_seconds}\"\n",
        "    else:\n",
        "      return f\"{timestamp}\"\n",
        "\n",
        "import concurrent.futures\n",
        "import time\n",
        "from deep_translator import GoogleTranslator\n",
        "\n",
        "def summarize(prompt):\n",
        "    completion = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[\n",
        "            {\"role\": \"system\", \"content\": summary_prompt},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            max_tokens=4096\n",
        "    )\n",
        "    return completion.choices[0].message.content\n",
        "\n",
        "def process_and_summarize(text,chunk_size):\n",
        "    overlap_size = 20\n",
        "    texts = [text[i:i+chunk_size] for i in range(0, len(text), chunk_size - overlap_size)]\n",
        "    cleaned_texts, timestamp_ranges = extract_and_clean_timestamps(texts)\n",
        "    summaries = []\n",
        "\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=parallel_api_calls) as executor:\n",
        "        future_to_chunk = {executor.submit(summarize, text_chunk): idx for idx, text_chunk in enumerate(cleaned_texts)}\n",
        "        for future in concurrent.futures.as_completed(future_to_chunk):\n",
        "            idx = future_to_chunk[future]\n",
        "            try:\n",
        "                summarized_chunk = future.result()\n",
        "                summary_piece = format_timestamp_link(timestamp_ranges[idx]) + \" \" + summarized_chunk\n",
        "                summary_piece += \"\\n\"\n",
        "                summaries.append((idx, summary_piece))\n",
        "            except Exception as exc:\n",
        "                print(f'Chunk {idx} generated an exception: {exc}')\n",
        "                # Resubmit the task with the new model\n",
        "                time.sleep(10)\n",
        "                future_to_chunk[executor.submit(summarize, texts[idx])] = idx\n",
        "\n",
        "    summaries.sort()  # Ensure summaries are in the correct order\n",
        "    final_summary =\"\"\n",
        "    if Translate_to != \"English\":\n",
        "      translated_summaries = []\n",
        "      for _,summary in summaries:\n",
        "        translated_summary = GoogleTranslator(source='auto', target=language_codes[Translate_to]).translate(summary)\n",
        "        translated_summaries.append(translated_summary)\n",
        "        final_summary += translated_summary + \"\\n\\n\"\n",
        "      final_summary = final_summary.strip()\n",
        "    else :\n",
        "      final_summary = \"\\n\\n\".join([summary for _, summary in summaries])\n",
        "\n",
        "    # Save the final summary\n",
        "    final_name = transcript_file_name.replace(\".md\", \"_FINAL_\"+str(chunk_size)+\".md\") if Type != \"Dropbox video link\" else \"final_dropbox_video.md\"\n",
        "    with open(final_name, 'w') as f:\n",
        "        f.write(final_summary)\n",
        "    return (final_summary)\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell # Unblock output\n",
        "InteractiveShell.ast_node_interactivity = \"all\"            # It starts to work after restart cell\n",
        "#%config InteractiveShell.ast_node_interactivity=\"all\"\n",
        "clear_output()\n",
        "print (\"Generating summary...\")\n",
        "general_summary = process_and_summarize(text,15000) # max string size = max_tokens x 4\n",
        "IPython.display.Markdown(\"\\n\\n **Short Summary:** \\n\\n\" + general_summary)\n",
        "final_summary = process_and_summarize(text,3072)\n",
        "clear_output()\n",
        "IPython.display.Markdown(\"\\n\\n **Short Summary:** \\n\\n\" + general_summary + \"\\n\\n\" + \"\\n\\n **Long Summary:** \\n\\n\" + final_summary )\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}