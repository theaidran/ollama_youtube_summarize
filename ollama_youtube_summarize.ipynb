{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/theaidran/ollama_youtube_summarize/blob/main/ollama_youtube_summarize.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title #####  Put a YouTube link below and hit Run a cell. Use any-language video and get any-language summary. Quick access to this colab notebook. [tinyurl.com/summarisation](https://tinyurl.com/summarisation) { display-mode: \"form\" }\n",
        "%config InteractiveShell.ast_node_interactivity=\"all\" #update python display config"
        "!pip install openai==1.55.3 --quiet"
        "!pip install httpx==0.27.2 --quiet"
      ],
      "metadata": {
        "collapsed": true,
        "id": "PddpLm1hdgvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jwROe6WH2lZi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c57edb37-d3ff-4f6e-ab3a-5a743c5ccb38"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n\n **Short Summary:** \n\n00:00:00 - https://www.youtube.com/watch?v=t6VoqbAh9HM&t=0 **\"Automating Website Content Creation with AI Tools: A Step-by-Step Guide\"**\n\nThe video transcript excerpt discusses the process of using artificial intelligence (AI) tools, such as ChatGPT and Claude, to generate content for a website. The creator starts by writing prompts that guide the AI models in producing desired content styles. In this case, the prompt is designed to mimic the style of Alex Horoi.\n\nThe AI model generates a heading and subheading for the website: \"The Ultimate Drone Buyer Guide: Soar to New Heights with the Perfect UAV\" and \"Discover the Best Drones for Your Needs and Budget: Expert Reviews, Side-by-Side Comparisons, and Insider Tips to Help You Make an Informed Decision.\"\n\nThe creator then uses Claude to generate images for the website. They choose a prompt and settings to create realistic images. The generated image is of a camera drone flying above a city skyline, which is then downloaded and added to the website.\n\nFinally, the excerpt touches on using Canva to create featured images for blog posts, highlighting its ease of use and capabilities in adding text, removing backgrounds, and manipulating images.\n\n\n00:11:15 - https://www.youtube.com/watch?v=t6VoqbAh9HM&t=675 **Building a Website with AI: A Step-by-Step Guide**\n\nAs we continue to explore the world of AI-powered website building, our narrator delves into the process of creating a featured image using Canva. They demonstrate how to generate images or graphics, choosing a style and theme that fits their needs. In this case, they use the \"Magic Media\" tool to create a city skyline image, complete with a drone flying overhead.\n\nThe narrator then explains how they can edit the image further by removing its background using AI features. They select a new background image of themselves pointing at the drone, and adjust its outline to make it stand out. Finally, they add text to the image, using a font that matches their website's style, and apply some effects to make it pop.\n\nThroughout this process, our narrator highlights various AI tools used in website building, including Reloom for creating site maps, Color Mind for generating color schemes, Font Joy for finding font pairings, ChatGPT or Claude for writing copy, and Mid Journey (or other image generators) for creating images. They emphasize that while these AI tools can be incredibly powerful, some manual tweaking is still required to achieve the desired outcome.\n\nThe video concludes with a call-to-action, encouraging viewers to explore Future Tools for more AI-related content, including news, tool reviews, and giveaways.\n\n\n\n\n **Long Summary:** \n\n00:00:00 - https://www.youtube.com/watch?v=t6VoqbAh9HM&t=0 **Getting Started with AI-Enabled Website Building**\n\nThe speaker is emphasizing the importance of having a website, whether for sharing thoughts and ideas, selling products or digital courses. They're excited to share some AI-enabled tools that can help anyone get a website online quickly and easily, without requiring technical knowledge. The first tool they'll be exploring is called Reloom, found at rom.io. This tool uses AI to map out an entire website, with a free plan that's free forever for developing simple websites, as well as premium plans for those using design tools like Web Flow and Figma.\n\n\n00:02:18 - https://www.youtube.com/watch?v=t6VoqbAh9HM&t=138 **Building a Website with AI**\n\nAs they navigate through the website creation process, Wolf recommends using Hostinger as their hosting provider. He takes advantage of the sponsorship deal, allowing viewers to get a website for as little as $2.99 a month and two months free. With Hostinger's AI-powered WordPress builder, they're able to create a website in minutes.\n\nWolf chooses the Business website builder plan, which includes most of the AI tools. They fill out their details and apply a coupon code \"Matt wolf\" to get an even bigger discount. Once inside the hosting platform, they click on \"Add Website\" and opt for the AI-powered website creator. Wolf names their site \"Drone World,\" sets up a blog with a spoken description, and lets AI build their website.\n\nIn just a few clicks, the AI has set up a live website, complete with pictures that automatically pulled in based on the context of the content. The website is simple to start, but can be edited to change anything Wolf wants. Before diving into site customization, they're excited to explore ColorM, a tool that uses machine learning to help with color schemes.\n\n\n00:04:34 - https://www.youtube.com/watch?v=t6VoqbAh9HM&t=274 **Integrating AI-Generated Colors and Fonts into a Website Design**\n\nAs our narrator continues, they highlight the ease of using Colormind, an AI-driven tool that generates color palettes. The user can start by generating a random palette and locking in colors they like, allowing Colormind to suggest matching hues. In this example, the user is pleased with the blue, yellow, and red colors and locks them in for further variation generation.\n\nWith the color scheme decided upon, our narrator emphasizes the importance of font selection using Font Joy, another AI-powered tool that recommends font pairings. By generating different font styles, they find a suitable main font (in this case, Robotto Condensed) and lock it in. The user then generates additional font suggestions until finding two more fonts that complement the chosen font: Work Sans and Hind Vad.\n\n\n00:06:48 - https://www.youtube.com/watch?v=t6VoqbAh9HM&t=408 **Building a Website with AI Assistance**\n\nThe speaker is continuing to work on building their website, focusing on adding content using the tools ChatGPT or Claude. They're explaining that these two models are similar in their capabilities, and the key is writing a prompt that gets the desired style of writing. The speaker decides to use Claude for this example, providing details about the site they're creating - a review website for drones. They ask Claude to write a header and subheader in the style of Alex Horoi or David Ogili, both well-known marketers, hoping it will yield better results.\n\n\n00:09:01 - https://www.youtube.com/watch?v=t6VoqbAh9HM&t=541 **Optimizing Website Images: Tips and Tools**\n\nAs we continue exploring the importance of visually appealing images on our website, let's focus on how to generate high-quality images that capture visitors' attention. The speaker starts by copying and pasting headings and subheadings into their website design, emphasizing the need for repetition throughout the site. They also highlight the value of using camera drones like the DJI Mavic 2 for capturing unique images.\n\nThe next step is to explore other image generation tools beyond what's already available. The speaker recommends Mid Journey, which offers a small fee for use, and Dolly 3, which can be used for free on Bing.com after recently opening up their website for public access.\n\nTo generate realistic images, the speaker adjusts settings on a camera drone flying above a city skyline, opting for \"Model Raw\" instead of standard. After submitting the image request, they wait for the generated image to appear and are pleased with the result, which can be downloaded and used on their website.\n\nThe speaker also discusses replacing default images on the website with new, more relevant ones created using image generation tools. They emphasize the importance of centering images correctly and suggest exploring different image generator options, as there are many good ones available today.\n\nFinally, the speaker shares their favorite tool for creating featured images for blog posts: Canva. This user-friendly platform allows for easy design creation, including adding text to images, removing backgrounds, and more. The speaker demonstrates how to use Canva to create a YouTube thumbnail, which can be applied to other types of featured images on the website.\n\n\n00:11:27 - https://www.youtube.com/watch?v=t6VoqbAh9HM&t=687 **Customizing Featured Images with Canva**\n\nThe creator is exploring ways to create consistent featured images for their blog posts using Magic Media's built-in image generator within Canva. They opt for a filmic style and generate images, selecting a few that meet their standards. One image in particular stands out, featuring a drone flying above a city skyline. To customize it further, they use AI-powered background remover to remove the original background and replace it with a new one from their own uploads. The goal is to make themselves stand out in the image, so they add a white outline around themselves, looking excitedly at the drone. Finally, they add text to the image using a font that matches their website's style, stretching it out to cover the entire image.\n\n\n00:13:31 - https://www.youtube.com/watch?v=t6VoqbAh9HM&t=811 **Automating Website Building with AI**\n\nAs the narrator continues, they're discussing the process of building a website using various AI tools. They've already created a featured image using Canva and AI features, adding effects such as a light drop shadow to make it pop. The goal is to create a website that looks like a multi-million dollar company would have, but acknowledges that AI isn't quite there yet. Instead, they're showing how to get \"pretty darn close\" with the available tools and some extra tweaking.\n\nThe narrator highlights their use of Reloom for site mapping, Hostinger (with a coupon code) for website building, Color Mind for color scheme selection, Font Joy for font pairings, Claude or Chat GPT for copywriting, and Canva for featured image creation. They've even used mid Journey, Leonardo, Dolly 3, or Bing Co-pilot for image generation.\n\nThe final step is to create a beautiful website by using AI tools, which may require some extra effort to \"dial in\" the design. The narrator concludes that these quick examples showcase what's possible with AI tools and encourages viewers who want more information on building websites using AI to let them know, as they're happy to create more videos like this.\n\n\n00:15:55 - https://www.youtube.com/watch?v=t6VoqbAh9HM&t=955 **Future Tools and Free Gadgets**\n\nAs our conversation continues, we find that Future Tools is a platform where AI tools are curated daily, keeping users up-to-date on the latest news. To stay in the loop, one can sign up for the free newsletter, which shares cool AI tools and important news. Additionally, by subscribing to the YouTube channel and joining the newsletter, viewers will be entered into a monthly drawing for a chance to win exciting gadgets, such as the Insta 360 X4 camera.\n"
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# @title  Summarize { run: \"auto\", display-mode: \"form\" }\n",
        "# All credits to https://github.com/martinopiaggi/summarize\n",
        "# Good to see links:\n",
        "# https://github.com/hsiehjackson/RULER\n",
        "# https://ollama.com/library\n",
        "# https://amgadhasan.substack.com/p/sota-asr-tooling-long-form-transcription\n",
        "\n",
        "\n",
        "#1 Choose source url\n",
        "Link = \"https://www.youtube.com/watch?v=t6VoqbAh9HM\" #@param {type:\"string\"}\n",
        "Type_of_source = \"Youtube video or playlist\" #@param ['Youtube video or playlist', 'Google Drive video link','Dropbox video link', 'Local file']\n",
        "Type = Type_of_source\n",
        "URL = Link\n",
        "Translate_to = \"English\" # @param ['Afrikaans', 'Albanian', 'Amharic', 'Arabic', 'Armenian', 'Azerbaijani', 'Basque', 'Belarusian', 'Bengali', 'Bosnian', 'Bulgarian', 'Catalan', 'Cebuano', 'Chinese (Simplified)', 'Chinese (Traditional)', 'Corsican', 'Croatian', 'Czech', 'Danish', 'Dutch', 'English', 'Esperanto', 'Estonian', 'Finnish', 'French', 'Frisian', 'Galician', 'Georgian', 'German', 'Greek', 'Gujarati', 'Haitian Creole', 'Hausa', 'Hawaiian', 'Hebrew', 'Hindi', 'Hmong', 'Hungarian', 'Icelandic', 'Igbo', 'Indonesian', 'Irish', 'Italian', 'Japanese', 'Javanese', 'Kannada', 'Kazakh', 'Khmer', 'Korean', 'Kurdish', 'Kyrgyz', 'Lao', 'Latin', 'Latvian', 'Lithuanian', 'Luxembourgish', 'Macedonian', 'Malagasy', 'Malay', 'Malayalam', 'Maltese', 'Maori', 'Marathi', 'Mongolian', 'Myanmar (Burmese)', 'Nepali', 'Norwegian', 'Nyanja (Chichewa)', 'Pashto', 'Persian', 'Polish', 'Portuguese (Portugal, Brazil)', 'Punjabi', 'Romanian', 'Russian', 'Samoan', 'Scots Gaelic', 'Serbian', 'Sesotho', 'Shona', 'Sindhi', 'Sinhala (Sinhalese)', 'Slovak', 'Slovenian', 'Somali', 'Spanish', 'Sundanese', 'Swahili', 'Swedish', 'Tagalog (Filipino)', 'Tajik', 'Tamil', 'Telugu', 'Thai', 'Turkish', 'Ukrainian', 'Urdu', 'Uzbek', 'Vietnamese', 'Welsh', 'Xhosa', 'Yiddish', 'Yoruba', 'Zulu']\n",
        "\n",
        "language_codes = {'Afrikaans': 'af', 'Albanian': 'sq', 'Amharic': 'am', 'Arabic': 'ar', 'Armenian': 'hy', 'Azerbaijani': 'az', 'Basque': 'eu', 'Belarusian': 'be', 'Bengali': 'bn', 'Bosnian': 'bs', 'Bulgarian': 'bg', 'Catalan': 'ca', 'Cebuano': 'ceb', 'Chinese (Simplified)': 'zh-CN', 'Chinese (Traditional)': 'zh-TW', 'Corsican': 'co', 'Croatian': 'hr', 'Czech': 'cs', 'Danish': 'da', 'Dutch': 'nl', 'English': 'en', 'Esperanto': 'eo', 'Estonian': 'et', 'Finnish': 'fi', 'French': 'fr', 'Frisian': 'fy', 'Galician': 'gl', 'Georgian': 'ka', 'German': 'de', 'Greek': 'el', 'Gujarati': 'gu', 'Haitian Creole': 'ht', 'Hausa': 'ha', 'Hawaiian': 'haw', 'Hebrew': 'iw', 'Hindi': 'hi', 'Hmong': 'hmn', 'Hungarian': 'hu', 'Icelandic': 'is', 'Igbo': 'ig', 'Indonesian': 'id', 'Irish': 'ga', 'Italian': 'it', 'Japanese': 'ja', 'Javanese': 'jw', 'Kannada': 'kn', 'Kazakh': 'kk', 'Khmer': 'km', 'Korean': 'ko', 'Kurdish': 'ku', 'Kyrgyz': 'ky', 'Lao': 'lo', 'Latin': 'la', 'Latvian': 'lv', 'Lithuanian': 'lt', 'Luxembourgish': 'lb', 'Macedonian': 'mk', 'Malagasy': 'mg', 'Malay': 'ms', 'Malayalam': 'ml', 'Maltese': 'mt', 'Maori': 'mi', 'Marathi': 'mr', 'Mongolian': 'mn', 'Myanmar (Burmese)': 'my', 'Nepali': 'ne', 'Norwegian': 'no', 'Nyanja (Chichewa)': 'ny', 'Pashto': 'ps', 'Persian': 'fa', 'Polish': 'pl', 'Portuguese (Portugal, Brazil)': 'pt', 'Punjabi': 'pa', 'Romanian': 'ro', 'Russian': 'ru', 'Samoan': 'sm', 'Scots Gaelic': 'gd', 'Serbian': 'sr', 'Sesotho': 'st', 'Shona': 'sn', 'Sindhi': 'sd', 'Sinhala (Sinhalese)': 'si', 'Slovak': 'sk', 'Slovenian': 'sl', 'Somali': 'so', 'Spanish': 'es', 'Sundanese': 'su', 'Swahili': 'sw', 'Swedish': 'sv', 'Tagalog (Filipino)': 'tl', 'Tajik': 'tg', 'Tamil': 'ta', 'Telugu': 'te', 'Thai': 'th', 'Turkish': 'tr', 'Ukrainian': 'uk', 'Urdu': 'ur', 'Uzbek': 'uz', 'Vietnamese': 'vi', 'Welsh': 'cy', 'Xhosa': 'xh', 'Yiddish': 'yi', 'Yoruba': 'yo', 'Zulu': 'zu'}\n",
        "\n",
        "#@markdown ---\n",
        "#markdown Insert your API key depending on which endpoint you want to use\n",
        "# API Configuration\n",
        "api_key = \"ollama\"\n",
        "api_endpoint = \"Custom\"\n",
        "ollama_model = \"llama3\" # param ['llama3', 'phi3', 'vicuna:13b-v1.5-16k-q4_0']\n",
        "\n",
        "endpoints = {\n",
        "    \"Groq\": \"https://api.groq.com/openai/v1\",\n",
        "    \"OpenAI\": \"https://api.openai.com/v1\",\n",
        "    \"Custom\": \"http://localhost:11434/v1\"  # ollama endpoint\n",
        "}\n",
        "base_url = endpoints.get(api_endpoint)\n",
        "\n",
        "models = {\n",
        "    \"Groq\": \"llama3-8b-8192\",\n",
        "    \"OpenAI\": \"gpt-3.5-turbo\",\n",
        "    \"Custom\": ollama_model  # Placeholder for any custlom model\n",
        "}\n",
        "model = models.get(api_endpoint)\n",
        "\n",
        "use_Youtube_captions = True #@param {type:\"boolean\"}\n",
        "# @markdown  * otherwise transcribe audio\n",
        "\n",
        "\n",
        "#2 launch ollama server with llama3\n",
        "try: # to faster next start\n",
        "  import pytubefix\n",
        "except ImportError:\n",
        "  !curl -fsSL https://ollama.com/install.sh | sh\n",
        "  !tmux new -d ollama serve\n",
        "  !ollama run {ollama_model} !\n",
        "\n",
        "\n",
        "#3 install libs: youtube and whisperx\n",
        "import subprocess\n",
        "import re\n",
        "import os\n",
        "import IPython\n",
        "from IPython.display import clear_output\n",
        "\n",
        "def install_whisperx():\n",
        "    try:\n",
        "      import whisperx\n",
        "    except ImportError:\n",
        "      print(\"installing whisperx...may take a few minutes\")\n",
        "      !pip install git+https://github.com/m-bain/whisperx.git > /dev/null\n",
        "      clear_output()\n",
        "\n",
        "if use_Youtube_captions:\n",
        "  !pip install youtube-transcript-api\n",
        "  from youtube_transcript_api import YouTubeTranscriptApi\n",
        "\n",
        "if (not Type == \"Youtube video or playlist\") or (not use_Youtube_captions):\n",
        "  install_whisperx()\n",
        "\n",
        "try:\n",
        "  import deep_translator\n",
        "except ImportError:\n",
        "  !pip install -U deep-translator\n",
        "\n",
        "try:\n",
        "  import openai\n",
        "except ImportError:\n",
        "  !pip install openai==1.55.3\n",
        "  !pip install httpx==0.27.2",
        "  #clear_output()\n",
        "\n",
        "import openai\n",
        "client = openai.OpenAI(api_key=api_key, base_url=base_url)\n",
        "\n",
        "if Type == \"Youtube video or playlist\":\n",
        "  try:\n",
        "    import pytubefix\n",
        "  except ImportError:\n",
        "    #!pip install git+https://github.com/pytube/pytube\n",
        "    !pip install git+https://github.com/JuanBindez/pytubefix\n",
        "    #clear_output()\n",
        "    from pytubefix import YouTube\n",
        "\n",
        "if Type == \"Google Drive video link\":\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "#4 Video fetching\n",
        "skip_transcription=False\n",
        "text = \"\"\n",
        "textTimestamps = \"\"\n",
        "\n",
        "def seconds_to_time_format(seconds):\n",
        "    hours, remainder = divmod(seconds, 3600)\n",
        "    minutes, seconds = divmod(remainder, 60)\n",
        "    return f\"{int(hours):02d}:{int(minutes):02d}:{int(seconds):02d}\"\n",
        "\n",
        "def download_youtube_audio_only(url):\n",
        "    yt = YouTube(url)\n",
        "    audio_stream = yt.streams.get_audio_only()\n",
        "    saved_path = audio_stream.download(output_path=\".\", skip_existing=True)\n",
        "    return saved_path\n",
        "\n",
        "def check_if_captions_exist(url):\n",
        "    regex = r'(?:https?:\\/\\/)?(?:www\\.)?(?:youtube\\.com\\/(?:[^\\/\\n\\s]+\\/\\S+\\/|(?:v|e(?:mbed)?)\\/|\\S*?[?&]v=)|youtu\\.be\\/)([a-zA-Z0-9_-]{11})'\n",
        "    video_id =  re.search(regex, url).group(1)\n",
        "\n",
        "    try:\n",
        "      transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\n",
        "      return (True)\n",
        "    except:\n",
        "      return (False)\n",
        "\n",
        "def download_youtube_captions(url):\n",
        "    regex = r'(?:https?:\\/\\/)?(?:www\\.)?(?:youtube\\.com\\/(?:[^\\/\\n\\s]+\\/\\S+\\/|(?:v|e(?:mbed)?)\\/|\\S*?[?&]v=)|youtu\\.be\\/)([a-zA-Z0-9_-]{11})'\n",
        "    video_id =  re.search(regex, url).group(1)\n",
        "    transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\n",
        "\n",
        "    try:\n",
        "      transcript = YouTubeTranscriptApi.get_transcript(video_id) #languages=['en']\n",
        "    except:\n",
        "      for available_transcript in transcript_list:\n",
        "        if available_transcript.is_translatable:\n",
        "          transcript = available_transcript.translate('en').fetch()\n",
        "          break\n",
        "\n",
        "    text = \"\"\n",
        "    for entry in transcript:\n",
        "            start_time = seconds_to_time_format(entry['start'])\n",
        "            text += f\"{start_time} {entry['text'].strip()}\\n\"\n",
        "\n",
        "    transcript_file_name = f\"{video_id}_captions.md\"\n",
        "\n",
        "    with open(transcript_file_name, 'w', encoding='utf-8') as f:\n",
        "      f.write(text)\n",
        "\n",
        "    return text,transcript_file_name\n",
        "\n",
        "if Type == \"Youtube video or playlist\":\n",
        "    #clean youtube url from timestamp\n",
        "    URL = re.sub('\\&t=\\d+s?', '', URL)\n",
        "\n",
        "    if use_Youtube_captions and check_if_captions_exist(URL):\n",
        "      text, transcript_file_name = download_youtube_captions(URL)\n",
        "      skip_transcription=True\n",
        "    else:\n",
        "      install_whisperx()\n",
        "      video_path_local =  download_youtube_audio_only(URL)\n",
        "\n",
        "elif Type == \"Google Drive video link\":\n",
        "  subprocess.run(['ffmpeg', '-y', '-i', 'drive/MyDrive/' + URL, '-vn', '-acodec', 'pcm_s16le',\n",
        "                  '-ar', '16000', '-ac', '1', 'gdrive_audio.wav'], check=True)\n",
        "  video_path_local = \"gdrive_audio.wav\"\n",
        "\n",
        "elif Type == \"Dropbox video link\":\n",
        "    subprocess.run(['wget', URL, '-O', 'dropbox_video.mp4'], check=True)\n",
        "    subprocess.run(['ffmpeg', '-y', '-i', 'dropbox_video.mp4', '-vn', '-acodec', 'pcm_s16le',\n",
        "                    '-ar', '16000', '-ac', '1', 'dropbox_video_audio.wav'], check=True)\n",
        "    video_path_local = \"dropbox_video_audio.wav\"\n",
        "\n",
        "elif Type == \"Local file\":\n",
        "    local_file_path = Source\n",
        "    subprocess.run(['ffmpeg', '-y', '-i', local_file_path, '-vn', '-acodec', 'pcm_s16le',\n",
        "                    '-ar', '16000', '-ac', '1', 'local_file_audio.wav'], check=True)\n",
        "    video_path_local = \"local_file_audio.wav\"\n",
        "\n",
        "\n",
        "#5 transcription using whisperx\n",
        "if not skip_transcription:\n",
        "  import whisperx\n",
        "  language = \"auto\" # param {type:\"string\"}\n",
        "  #initial_prompt = \"\" # @param {type:\"string\"}\n",
        "\n",
        "  asr_options={\"temperatures\": 0, \"beam_size\": 1, \"without_timestamps\": True,}\n",
        "  # Run on GPU with FP16\n",
        "  modelWhisperX = whisperx.load_model(\"large-v2\", device=\"cuda\", compute_type=\"float16\", asr_options=asr_options)\n",
        "\n",
        "  transcription = modelWhisperX.transcribe(str(video_path_local), batch_size=16,\n",
        "                                    language=None if language == \"auto\" else language,\n",
        "                                    task=\"translate\")\n",
        "\n",
        "  transcript_file_name = os.path.splitext(video_path_local)[0]+'.md'\n",
        "\n",
        "  with open(transcript_file_name, 'w') as f:\n",
        "    for segment in transcription[\"segments\"]:\n",
        "        start_time = seconds_to_time_format(segment['start'])\n",
        "        text += f\"{start_time} {segment['text'].strip()} \"\n",
        "\n",
        "    f.write(text)\n",
        "\n",
        "\n",
        "#6 Make a summary\n",
        "prompt_type = \"Summarization\"  # param ['Summarization', 'Only grammar correction with highlights']\n",
        "# markdown Set the number of parallel API calls (be mindful of usage rate limits)\n",
        "parallel_api_calls = 1 # param\n",
        "\n",
        "\n",
        "# Define your prompts using a dictionary for easier management\n",
        "prompts = {\n",
        "    'Summarization': \"\"\"Summarize the video transcript excerpt, including a bold title. Use narration in third-person. Write the summary as if you are continuing a conversation without needing to signal a beginning. Here is the transcript: \"\"\",\n",
        "    'Only grammar correction with highlights': \"\"\"Repeat the following text correcting any grammatical errors and formatting error. Highlight only the important quote (if there are any) with **markdown bold notation**. Focus solely on the essence of the content as if you are continuing a conversation without using any form of introduction like 'Here's the corrected text:'. Here is the text to fix: \"\"\"\n",
        "}\n",
        "\n",
        "# Select the appropriate prompt\n",
        "summary_prompt = prompts[prompt_type]\n",
        "\n",
        "\n",
        "\n",
        "def extract_and_clean_timestamps(text_chunks):\n",
        "    timestamp_pattern = re.compile(r'(\\d{2}:\\d{2}:\\d{2})')\n",
        "    cleaned_texts = []\n",
        "    timestamp_ranges = []\n",
        "    for chunk in text_chunks:\n",
        "        timestamps = timestamp_pattern.findall(chunk)\n",
        "        if timestamps:\n",
        "            for timestamp in timestamps:\n",
        "                # Remove each found timestamp from the chunk\n",
        "                chunk = chunk.replace(timestamp, \"\")\n",
        "            timestamp_ranges.append(timestamps[0])  # Assuming you want the first timestamp per chunk\n",
        "        else:\n",
        "            timestamp_ranges.append(\"\")\n",
        "        cleaned_texts.append(chunk.strip())  # Strip to remove any leading/trailing whitespace\n",
        "    return cleaned_texts, timestamp_ranges\n",
        "\n",
        "def format_timestamp_link(timestamp):\n",
        "    if Type == \"Youtube video or playlist\":\n",
        "      hours, minutes, seconds = map(int, timestamp.split(':'))\n",
        "      total_seconds = hours * 3600 + minutes * 60 + seconds\n",
        "      return f\"{timestamp} - {URL}&t={total_seconds}\"\n",
        "    else:\n",
        "      return f\"{timestamp}\"\n",
        "\n",
        "import concurrent.futures\n",
        "import time\n",
        "from deep_translator import GoogleTranslator\n",
        "\n",
        "def summarize(prompt):\n",
        "    completion = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[\n",
        "            {\"role\": \"system\", \"content\": \"\"},\n",
        "            {\"role\": \"user\", \"content\": summary_prompt + \" \" + prompt}\n",
        "            ],\n",
        "            max_tokens=4096\n",
        "    )\n",
        "    return completion.choices[0].message.content\n",
        "\n",
        "def process_and_summarize(text,chunk_size):\n",
        "    overlap_size = 20\n",
        "    texts = [text[i:i+chunk_size] for i in range(0, len(text), chunk_size - overlap_size)]\n",
        "    cleaned_texts, timestamp_ranges = extract_and_clean_timestamps(texts)\n",
        "    summaries = []\n",
        "\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=parallel_api_calls) as executor:\n",
        "        future_to_chunk = {executor.submit(summarize, text_chunk): idx for idx, text_chunk in enumerate(cleaned_texts)}\n",
        "        for future in concurrent.futures.as_completed(future_to_chunk):\n",
        "            idx = future_to_chunk[future]\n",
        "            try:\n",
        "                summarized_chunk = future.result()\n",
        "                summary_piece = format_timestamp_link(timestamp_ranges[idx]) + \" \" + summarized_chunk\n",
        "                summary_piece += \"\\n\"\n",
        "                summaries.append((idx, summary_piece))\n",
        "            except Exception as exc:\n",
        "                print(f'Chunk {idx} generated an exception: {exc}')\n",
        "                # Resubmit the task with the new model\n",
        "                time.sleep(10)\n",
        "                future_to_chunk[executor.submit(summarize, texts[idx])] = idx\n",
        "\n",
        "    summaries.sort()  # Ensure summaries are in the correct order\n",
        "    final_summary =\"\"\n",
        "    if Translate_to != \"English\":\n",
        "      translated_summaries = []\n",
        "      for _,summary in summaries:\n",
        "        translated_summary = GoogleTranslator(source='auto', target=language_codes[Translate_to]).translate(summary)\n",
        "        translated_summaries.append(translated_summary)\n",
        "        final_summary += translated_summary + \"\\n\\n\"\n",
        "      final_summary = final_summary.strip()\n",
        "    else :\n",
        "      final_summary = \"\\n\\n\".join([summary for _, summary in summaries])\n",
        "\n",
        "    # Save the final summary\n",
        "    final_name = transcript_file_name.replace(\".md\", \"_FINAL_\"+str(chunk_size)+\".md\") if Type != \"Dropbox video link\" else \"final_dropbox_video.md\"\n",
        "    with open(final_name, 'w') as f:\n",
        "        f.write(final_summary)\n",
        "    return (final_summary)\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell # Unblock output\n",
        "InteractiveShell.ast_node_interactivity = \"all\"            # It starts to work after restart cell\n",
        "#%config InteractiveShell.ast_node_interactivity=\"all\"\n",
        "clear_output()\n",
        "print (\"Generating summary...\")\n",
        "general_summary = process_and_summarize(text,15000) # max string size = max_tokens x 4\n",
        "IPython.display.Markdown(\"\\n\\n **Short Summary:** \\n\\n\" + general_summary)\n",
        "final_summary = process_and_summarize(text,3072)\n",
        "clear_output()\n",
        "IPython.display.Markdown(\"\\n\\n **Short Summary:** \\n\\n\" + general_summary + \"\\n\\n\" + \"\\n\\n **Long Summary:** \\n\\n\" + final_summary )\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "cell_execution_strategy": "setup",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
